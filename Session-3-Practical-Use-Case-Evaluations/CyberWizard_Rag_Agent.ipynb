{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"title-slide\">\n",
    "  \n",
    "# Module 3.1 -  Practical Use Case Evaluations   \n",
    "<span style=\"font-size:20px; line-height:2;\">\n",
    "Dr. Hari Manassery Koduvely <br> \n",
    "Principal Data Scientist  <br>  \n",
    "Cybersecurity Analytics <br>  \n",
    "Ottawa, Canada <br>  \n",
    "January 28, 2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Recap of Sessions 1 & 2   \n",
    "- <span style=\"font-size:18px;\">**GenAI Application** evaluation as a Holistic Process.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Reference-Based** and **Reference-Free** Evaluations.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Classical Metrics** for Reference-Based Evaluations.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**LLM-as-a-Judge** method</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Prompt Guidelines** for LLM-as-a-Judge method</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Biases** in  LLM-as-a-Judge method and their mitigations.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> Introdution to Observability</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> How to instrument Observability using **Open Telemetry**</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> **G-Eval** and **RAGAS** Frameworks</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> Open Source tool **DeepEval** </span>   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesssion 3 Learning Objectives  \n",
    "- <span style=\"font-size:18px;\">How to collect observability data from a real-world GenAI business application.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">How to use the observability data for evaluation using LLM-as-a-Judge Method.</span>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Use Case: A CyberWizard RAG Agent \n",
    "- <span style=\"font-size:18px;\">An **Agentic RAG AI Assistant** capable of answering any Cybersecurity related questions for assisting **Cyber Security Analysts**.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Depending on the users question, the agent decides whether to:</span>  \n",
    "    - <span style=\"font-size:18px;\">Look up a **MITRE knowledgebase** hosted locally in a vector database to get information about a particular attack TTP.</span>  \n",
    "    - <span style=\"font-size:18px;\">Call **Virus Total API** to find whether a particular file hash belongs to any known malware family.</span>   \n",
    "      \n",
    "    - <span style=\"font-size:18px;\">Call **National Vulnerability Database API** to find details about a known software vulnerability.</span>  \n",
    "      \n",
    "- <span style=\"font-size:18px;\">**Summarize the result using an LLM** and return the answer to the user.</span>  \n",
    "\n",
    "## What you'll learn\n",
    "- <span style=\"font-size:18px;\">How to set up a **RAG Agent** using **Strands Agent SDK** on AwS with observability instrumented using **OpenTelemetry**.</span>    \n",
    "   \n",
    "- <span style=\"font-size:18px;\">How to visualize agent traces on **Amazon CloudWatch** and **Amazon CloudTrail** and collect the data to a S3 bucket for further analysis.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">How to use the **LLM-as-a-Judge** method to assess the **Tool Calling** and **RAG Retrieval** performances of the CyberWizard Agent.</span>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: [Amazon Bedrock AgentCore Tutorials](https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/main/01-tutorials)  \n",
    "![image.png](../Images/amazon_bedrock_agentcore_tutorials.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites\n",
    "- <span style=\"font-size:18px;\">Enable transaction search on Amazon CloudWatch:</span>   \n",
    "  \n",
    "    - <span style=\"font-size:18px;\"> First-time users must enable CloudWatch Transaction Search to view Bedrock AgentCore spans and traces.</span>      \n",
    "      \n",
    "    - <span style=\"font-size:18px;\">To enable transaction search, refer to the AWS [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Enable-TransactionSearch.html).</span>  \n",
    "      \n",
    "- <span style=\"font-size:18px;\">Log group and Log stream configured on Amazon Cloudwatch to be added to the environment variables.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">AWS account with Amazon Bedrock Model access to Claude Haiku 4.5 with Model ID: global.anthropic.claude-haiku-4-5-20251001-v1:0</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">AWS credentials configured using `aws configure`</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">.env file updated with environment variables variables.</span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "<span style=\"font-size:18px;\"> Install the required dependencies mentioned in requirements.txt file.</span>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export AWS_PROFILE=628896215736_Fed_Developer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying the Pre-requisites\n",
    "\n",
    "<span style=\"font-size:18px;\"> Create a **log group** and a **log stream** for AgentCore observability. </span>  \n",
    "  \n",
    "<span style=\"font-size:18px;\"> This can be done either using the script below or from AWS CloudWatch UI. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "cloudwatch_client = boto3.client(\"logs\", region_name=\"us-gov-east-1\")\n",
    "response = cloudwatch_client.create_log_group(\n",
    "    logGroupName='agents/cyberwizard-rag-agent'\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cloudwatch_client.create_log_stream(\n",
    "    logGroupName='agents/cyberwizard-rag-agent',\n",
    "    logStreamName='default'\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enabling transactional search\n",
    "\n",
    "<span style=\"font-size:18px;\"> To run this example you first need to enable transactional search.</span>     \n",
    "<span style=\"font-size:18px;\"> You can do so in the AWS console following this [link](https://console.aws.amazon.com/cloudwatch/home#xray:settings/transaction-search).</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\"> Once in this page, click on edit and set the option to ingest spans as structured logs in the OpenTelemetry format </span>  \n",
    "![image.png](../Images/transactional_search.png)\n",
    "![image.png](../Images/transactional_search2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration\n",
    "<span style=\"font-size:18px;\"> To enable observability for your Strands agent and send telemetry data to Amazon CloudWatch, you'll need to configure the following environment variables.</span>     \n",
    "<span style=\"font-size:18px;\"> We use a `.env` file to manage these settings securely, keeping sensitive AWS credentials separate from your code while making it easy to switch between different environments.</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\">**Ensure your AWS credentials are configured**.</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\">We will create a `.env` file for configuring the environment variables. Use `Strands/.env.example` as a template.</span>\n",
    "\n",
    "<span style=\"font-size:18px;\">Required Environment Variables:</span>\n",
    "\n",
    "| Variable | Value | Purpose |\n",
    "|----------|-------|---------|\n",
    "| `OTEL_PYTHON_DISTRO` | `aws_distro` | Use AWS Distro for OpenTelemetry (ADOT) |\n",
    "| `OTEL_PYTHON_CONFIGURATOR` | `aws_configurator` | Set AWS configurator for ADOT SDK |\n",
    "| `OTEL_EXPORTER_OTLP_PROTOCOL` | `http/protobuf` | Configure export protocol |\n",
    "| `OTEL_EXPORTER_OTLP_LOGS_HEADERS` | `x-aws-log-group=<YOUR-LOG-GROUP>,x-aws-log-stream=<YOUR-LOG-STREAM>,x-aws-metric-namespace=<YOUR-NAMESPACE>` | Direct logs to CloudWatch groups |\n",
    "| `OTEL_RESOURCE_ATTRIBUTES` | `service.name=<YOUR-AGENT-NAME>` | Identify your agent in observability data |\n",
    "| `AGENT_OBSERVABILITY_ENABLED` | `true` | Activate ADOT pipeline |\n",
    "| `AWS_REGION` | `<YOUR-REGION>` | AWS Region |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Environment Variables\n",
    "\n",
    "<span style=\"font-size:18px;\">Load the environment variables from the `.env` file:</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Configuration:\n",
      "OTEL_PYTHON_DISTRO=aws_distro\n",
      "OTEL_PYTHON_CONFIGURATOR=aws_configurator\n",
      "OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n",
      "OTEL_EXPORTER_OTLP_LOGS_HEADERS=x-aws-log-group=agents/cyberwizard-rag-agent,x-aws-log-stream=default,x-aws-metric-namespace=bedrock-agentcore\n",
      "OTEL_RESOURCE_ATTRIBUTES=service.name=cyberwizard-rag-agent\n",
      "AGENT_OBSERVABILITY_ENABLED=true\n",
      "OTEL_TRACES_EXPORTER=otlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Display the OTEL-related environment variables\n",
    "otel_vars = [\n",
    "    \"OTEL_PYTHON_DISTRO\",\n",
    "    \"OTEL_PYTHON_CONFIGURATOR\",\n",
    "    \"OTEL_EXPORTER_OTLP_PROTOCOL\",\n",
    "    \"OTEL_EXPORTER_OTLP_LOGS_HEADERS\",\n",
    "    \"OTEL_RESOURCE_ATTRIBUTES\",\n",
    "    \"AGENT_OBSERVABILITY_ENABLED\",\n",
    "    \"OTEL_TRACES_EXPORTER\"\n",
    "]\n",
    "\n",
    "print(\"OpenTelemetry Configuration:\")\n",
    "for var in otel_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\"{var}={value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Strands Agent in a python file\n",
    "\n",
    "<span style=\"font-size:18px;\">CyberWizard Agent implementation is provided in `cyberwizard_rag_agent.py`.</span>  \n",
    "  \n",
    "<span style=\"font-size:18px;\"> It is Agentic RAG AI Assistant capable of answering any Cybersecurity related questions for assisting Cyber Threat Analysts.</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\">The Agent is Configured with the following: </span>   \n",
    "\n",
    "- <span style=\"font-size:18px;\"> A system prompt that defines the agent's role as a Cybersecurity Expert.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> Amazon Bedrock's Claude Haiku model as it's Large Language Model.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> A **Vector DB** serach tool for retrieving MITRE ATT&CK framework related information.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> A tool to query **Virus Total** API.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> A tool to query **National Vulnerability Databasl** API.</span>    \n",
    "\n",
    "<span style=\"font-size:18px;\"> The AWS OpenTelemetry distro will automatically handle tracer provider setup when using `opentelemetry-instrument` command and invoke the python code.</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cyberwizard_rag_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cyberwizard_rag_agent.py\n",
    "#General imports\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import json\n",
    "import atexit\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from threading import Lock\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from urllib.parse import quote_plus\n",
    "from uuid import uuid4\n",
    "import requests\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# AWS imports\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from aws_xray_exporter import AwsXRaySpanExporter\n",
    "\n",
    "# Strands Agent SDK imports\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# OpenTelemetry imports\n",
    "from opentelemetry import baggage, context, trace\n",
    "from opentelemetry.instrumentation.botocore import BotocoreInstrumentor\n",
    "from opentelemetry.instrumentation.requests import RequestsInstrumentor\n",
    "from opentelemetry.sdk.extension.aws.trace.aws_xray_id_generator import AwsXRayIdGenerator\n",
    "from opentelemetry.sdk.resources import SERVICE_NAME, Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.sdk.trace.sampling import ParentBased, TraceIdRatioBased\n",
    "\n",
    "\n",
    "# Parse CLI arguments\n",
    "def parse_arguments():\n",
    "    \"\"\"Parse the CLI arguments that control session metadata and ingestion.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Strands Cybersecurity Agent with Session Tracking')\n",
    "    parser.add_argument('--session-id', \n",
    "                       type=str, \n",
    "                       required=True,\n",
    "                       help='Session ID to associate with this agent run')\n",
    "    parser.add_argument('--question',\n",
    "                       type=str,\n",
    "                       required=False,\n",
    "                       help='Cybersecurity investigation question for the agent to analyze')\n",
    "    parser.add_argument('--ingest-pdfs',\n",
    "                       action='store_true',\n",
    "                       help='When set, ingest PDFs from the local folder before running the agent')\n",
    "    parser.add_argument('--pdf-folder',\n",
    "                       type=str,\n",
    "                       default='pdf_files',\n",
    "                       help='Folder containing PDFs to ingest into the vector store')\n",
    "    return parser.parse_args()\n",
    "\n",
    "# Setup Session Id in OpenTelemetry\n",
    "def set_session_context(session_id):\n",
    "    \"\"\"Set the session ID in OpenTelemetry baggage for trace correlation\"\"\"\n",
    "    ctx = baggage.set_baggage(\"session.id\", session_id)\n",
    "    token = context.attach(ctx)\n",
    "    logging.info(f\"Session ID '{session_id}' attached to telemetry context\")\n",
    "    return token\n",
    "\n",
    "###########################\n",
    "#### Agent Code below: ####\n",
    "###########################\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure Strands logging\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# AWS S3 Log Handler\n",
    "S3_BUCKET_ENV = \"AGENT_LOG_BUCKET\"\n",
    "S3_PREFIX_ENV = \"AGENT_LOG_PREFIX\"\n",
    "S3_BUFFER_BYTES_ENV = \"AGENT_LOG_MAX_BUFFER\"\n",
    "_s3_log_handler = None\n",
    "\n",
    "class S3LogHandler(logging.Handler):\n",
    "    \"\"\"Buffer logs locally and periodically upload them to a S3 bucket.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bucket_name: str,\n",
    "        prefix: str = \"cloudwatch-export\",\n",
    "        session_id: Optional[str] = None,\n",
    "        client=None,\n",
    "        max_bytes: int = 262_144,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.bucket_name = bucket_name\n",
    "        self.session_id = session_id or \"unknown-session\"\n",
    "        self._prefix = prefix.strip(\"/\") or \"cloudwatch-export\"\n",
    "        self._client = client or boto3.client(\"s3\")\n",
    "        self._buffer = StringIO()\n",
    "        self._lock = Lock()\n",
    "        self._run_id = uuid4().hex\n",
    "        self._sequence = 0\n",
    "        self._max_bytes = max(4096, int(max_bytes))\n",
    "\n",
    "    def set_session_id(self, session_id: Optional[str]) -> None:\n",
    "        \"\"\"Refresh the session identifier used in generated log keys.\"\"\"\n",
    "        if session_id:\n",
    "            self.session_id = session_id\n",
    "\n",
    "    def emit(self, record: logging.LogRecord) -> None:\n",
    "        \"\"\"Format a log record, buffer it, and flush if the buffer is full.\"\"\"\n",
    "        try:\n",
    "            message = self.format(record)\n",
    "        except Exception:  # pragma: no cover - fallback path\n",
    "            message = record.getMessage()\n",
    "\n",
    "        payload = None\n",
    "        with self._lock:\n",
    "            self._buffer.write(message + \"\\n\")\n",
    "            if self._buffer.tell() >= self._max_bytes:\n",
    "                payload = self._drain_buffer_locked()\n",
    "\n",
    "        if payload:\n",
    "            self._upload_payload(payload)\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        \"\"\"Force a buffered upload regardless of the current buffer size.\"\"\"\n",
    "        payload = None\n",
    "        with self._lock:\n",
    "            payload = self._drain_buffer_locked()\n",
    "        if payload:\n",
    "            self._upload_payload(payload)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Flush remaining bytes and release resources.\"\"\"\n",
    "        try:\n",
    "            self.flush()\n",
    "        finally:\n",
    "            try:\n",
    "                self._buffer.close()\n",
    "            except Exception:  # pragma: no cover - defensive\n",
    "                pass\n",
    "            super().close()\n",
    "\n",
    "    def _drain_buffer_locked(self) -> Optional[Tuple[str, bytes]]:\n",
    "        \"\"\"Return the current buffer contents as bytes and reset the buffer.\"\"\"\n",
    "        contents = self._buffer.getvalue()\n",
    "        if not contents.strip():\n",
    "            return None\n",
    "        self._buffer.close()\n",
    "        self._buffer = StringIO()\n",
    "        key = self._build_key()\n",
    "        return key, contents.encode(\"utf-8\")\n",
    "\n",
    "    def _build_key(self) -> str:\n",
    "        \"\"\"Generate a deterministic S3 object key for the current session.\"\"\"\n",
    "        self._sequence += 1\n",
    "        now = datetime.utcnow()\n",
    "        date_path = now.strftime(\"%Y/%m/%d\")\n",
    "        filename = f\"{self._sanitize(self.session_id)}-{now.strftime('%H%M%S')}-{self._run_id}-{self._sequence:04d}.log\"\n",
    "        return f\"{self._prefix}/{date_path}/{filename}\"\n",
    "\n",
    "    def _sanitize(self, value: str) -> str:\n",
    "        \"\"\"Replace unsafe characters in path components with hyphens.\"\"\"\n",
    "        safe = [ch if ch.isalnum() or ch in (\"-\", \"_\") else \"-\" for ch in value[:80]]\n",
    "        return \"\".join(safe) or \"session\"\n",
    "\n",
    "    def _upload_payload(self, payload: Tuple[str, bytes]) -> None:\n",
    "        \"\"\"Send the buffered payload to S3 and log the outcome locally.\"\"\"\n",
    "        key, data = payload\n",
    "        try:\n",
    "            self._client.put_object(Bucket=self.bucket_name, Key=key, Body=data)\n",
    "            print(f\"[S3LogHandler] Uploaded logs to s3://{self.bucket_name}/{key}\")\n",
    "        except Exception as exc:  # pragma: no cover - network errors\n",
    "            print(f\"[S3LogHandler] Failed to upload logs to s3://{self.bucket_name}/{key}: {exc}\")\n",
    "\n",
    "\n",
    "def configure_s3_log_archival(session_id: Optional[str]) -> Optional[S3LogHandler]:\n",
    "    \"\"\"Ensure the shared S3 log handler exists and is bound to the session.\"\"\"\n",
    "    global _s3_log_handler\n",
    "    bucket = os.getenv(S3_BUCKET_ENV)\n",
    "    if not bucket:\n",
    "        return None\n",
    "\n",
    "    max_buffer = os.getenv(S3_BUFFER_BYTES_ENV, \"262144\")\n",
    "    try:\n",
    "        max_buffer_bytes = int(max_buffer)\n",
    "    except ValueError:\n",
    "        logger.warning(\n",
    "            \"Invalid %s value '%s'. Using default buffer size.\",\n",
    "            S3_BUFFER_BYTES_ENV,\n",
    "            max_buffer,\n",
    "        )\n",
    "        max_buffer_bytes = 262_144\n",
    "\n",
    "    if _s3_log_handler is None:\n",
    "        prefix = os.getenv(S3_PREFIX_ENV, \"cloudwatch-export\")\n",
    "        handler = S3LogHandler(\n",
    "            bucket_name=bucket,\n",
    "            prefix=prefix,\n",
    "            session_id=session_id,\n",
    "            max_bytes=max_buffer_bytes,\n",
    "        )\n",
    "        handler.setLevel(logging.INFO)\n",
    "        handler.setFormatter(\n",
    "            logging.Formatter(\"%(asctime)s %(levelname)s [%(name)s] %(message)s\")\n",
    "        )\n",
    "        logging.getLogger().addHandler(handler)\n",
    "        _s3_log_handler = handler\n",
    "        atexit.register(handler.close)\n",
    "        logger.info(\"S3 log archival enabled (bucket=%s, prefix=%s)\", bucket, prefix)\n",
    "    else:\n",
    "        _s3_log_handler.set_session_id(session_id)\n",
    "\n",
    "    return _s3_log_handler\n",
    "\n",
    "\n",
    "def _parse_sample_ratio(value: str) -> float:\n",
    "    \"\"\"Safely coerce the OTEL sampling ratio into the valid [0, 1] range.\"\"\"\n",
    "    try:\n",
    "        ratio = float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        logger.warning(\"Invalid OTEL_TRACES_SAMPLER_ARG '%s'. Falling back to 1.0\", value)\n",
    "        return 1.0\n",
    "    return min(1.0, max(0.0, ratio))\n",
    "\n",
    "# sets up an in-process OpenTelemetry tracer that exports spans to AWS X-Ray \n",
    "# and instruments HTTP (requests) and AWS SDK (botocore) calls \n",
    "def configure_aws_tracing() -> None:\n",
    "    \"\"\"Configure an in-process AWS X-Ray exporter (Option 2).\"\"\"\n",
    "    if os.getenv(\"STRANDS_DISABLE_CUSTOM_XRAY\") in {\"1\", \"true\", \"True\"}:\n",
    "        logger.info(\"Custom AWS X-Ray exporter disabled via STRANDS_DISABLE_CUSTOM_XRAY\")\n",
    "        return\n",
    "\n",
    "    region = (\n",
    "        os.getenv(\"AWS_TRACES_REGION\")\n",
    "        or os.getenv(\"AWS_REGION\")\n",
    "        or os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        or \"us-east-1\"\n",
    "    )\n",
    "    service_name = os.getenv(\"OTEL_SERVICE_NAME\", \"cyberwizard-rag-agent\")\n",
    "    resource_attrs = {SERVICE_NAME: service_name}\n",
    "    if service_version := os.getenv(\"SERVICE_VERSION\"):\n",
    "        resource_attrs[\"service.version\"] = service_version\n",
    "    if service_namespace := os.getenv(\"SERVICE_NAMESPACE\"):\n",
    "        resource_attrs[\"service.namespace\"] = service_namespace\n",
    "\n",
    "    sample_ratio = _parse_sample_ratio(os.getenv(\"OTEL_TRACES_SAMPLER_ARG\", \"1.0\"))\n",
    "\n",
    "    tracer_provider = TracerProvider(\n",
    "        resource=Resource.create(resource_attrs),\n",
    "        id_generator=AwsXRayIdGenerator(),\n",
    "        sampler=ParentBased(TraceIdRatioBased(sample_ratio)),\n",
    "    )\n",
    "    exporter = AwsXRaySpanExporter(region=region, service_name=service_name)\n",
    "    tracer_provider.add_span_processor(BatchSpanProcessor(exporter))\n",
    "    trace.set_tracer_provider(tracer_provider)\n",
    "    logger.info(\n",
    "        \"AWS X-Ray tracing configured (region=%s, service=%s, sample_ratio=%s)\",\n",
    "        region,\n",
    "        service_name,\n",
    "        sample_ratio,\n",
    "    )\n",
    "\n",
    "    requests_instrumentor = RequestsInstrumentor()\n",
    "    try:\n",
    "        already_requests = requests_instrumentor.is_instrumented()  # type: ignore[attr-defined]\n",
    "    except AttributeError:\n",
    "        already_requests = False\n",
    "    if not already_requests:\n",
    "        try:\n",
    "            requests_instrumentor.instrument()\n",
    "        except Exception as exc:  # pragma: no cover - guard against re-entry issues\n",
    "            logger.warning(\"Requests instrumentation failed: %s\", exc)\n",
    "\n",
    "    botocore_instrumentor = BotocoreInstrumentor()\n",
    "    try:\n",
    "        already_botocore = botocore_instrumentor.is_instrumented()  # type: ignore[attr-defined]\n",
    "    except AttributeError:\n",
    "        already_botocore = False\n",
    "    if not already_botocore:\n",
    "        try:\n",
    "            botocore_instrumentor.instrument()\n",
    "        except Exception as exc:  # pragma: no cover\n",
    "            logger.warning(\"Botocore instrumentation failed: %s\", exc)\n",
    "\n",
    "\n",
    "configure_aws_tracing()\n",
    "\n",
    "# Local numpy-based Vector Store Implementation for RAG\n",
    "\n",
    "DEFAULT_VECTOR_DIR = \"vector_store\"\n",
    "\n",
    "def _resolve_vector_store_dir(override: Optional[str] = None) -> Path:\n",
    "    \"\"\"Resolve the folder that stores embeddings and metadata.\"\"\"\n",
    "    if override:\n",
    "        return Path(override)\n",
    "\n",
    "    for env_key in (\"VECTOR_STORE_DIR\", \"MITRE_VECTOR_DB_PATH\"):\n",
    "        configured = os.getenv(env_key)\n",
    "        if configured:\n",
    "            return Path(configured)\n",
    "\n",
    "    return Path(DEFAULT_VECTOR_DIR)\n",
    "\n",
    "\n",
    "def _vector_store_paths(store_dir: Path) -> Tuple[Path, Path]:\n",
    "    \"\"\"Return the embeddings.npy and documents.jsonl paths, ensuring the folder exists.\"\"\"\n",
    "    store_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return store_dir / \"embeddings.npy\", store_dir / \"documents.jsonl\"\n",
    "\n",
    "\n",
    "def _extend_vector_store(store_dir: Path, embeddings: List[List[float]], records: List[dict]) -> int:\n",
    "    \"\"\"Append new embeddings and records to the local vector store.\"\"\"\n",
    "    if not embeddings:\n",
    "        return 0\n",
    "\n",
    "    embeddings_path, documents_path = _vector_store_paths(store_dir)\n",
    "    new_array = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "    if embeddings_path.exists():\n",
    "        existing = np.load(embeddings_path)\n",
    "        existing = existing.astype(np.float32, copy=False)\n",
    "        new_array = np.vstack([existing, new_array])\n",
    "\n",
    "    np.save(embeddings_path, new_array)\n",
    "\n",
    "    with open(documents_path, \"a\", encoding=\"utf-8\") as doc_file:\n",
    "        for record in records:\n",
    "            doc_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    return len(records)\n",
    "\n",
    "\n",
    "def _load_vector_store(store_dir: Path) -> Tuple[Optional[np.ndarray], List[dict]]:\n",
    "    \"\"\"Load embeddings and associated metadata from disk.\"\"\"\n",
    "    embeddings_path, documents_path = _vector_store_paths(store_dir)\n",
    "\n",
    "    if not embeddings_path.exists() or not documents_path.exists():\n",
    "        return None, []\n",
    "\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    embeddings = embeddings.astype(np.float32, copy=False)\n",
    "\n",
    "    with open(documents_path, \"r\", encoding=\"utf-8\") as doc_file:\n",
    "        records = [json.loads(line) for line in doc_file if line.strip()]\n",
    "\n",
    "    if len(records) != len(embeddings):\n",
    "        logger.warning(\n",
    "            \"Vector store record count mismatch (records=%s, embeddings=%s). Truncating to smallest.\",\n",
    "            len(records),\n",
    "            len(embeddings),\n",
    "        )\n",
    "        min_len = min(len(records), len(embeddings))\n",
    "        embeddings = embeddings[:min_len]\n",
    "        records = records[:min_len]\n",
    "\n",
    "    return embeddings, records\n",
    "\n",
    "\n",
    "def _cosine_similarity_matrix(matrix: np.ndarray, vector: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute cosine similarity between a matrix of embeddings and a single vector.\"\"\"\n",
    "    if matrix.size == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    vector_norm = np.linalg.norm(vector)\n",
    "    if vector_norm == 0:\n",
    "        return np.zeros(matrix.shape[0])\n",
    "\n",
    "    normalized_vector = vector / vector_norm\n",
    "    matrix_norms = np.linalg.norm(matrix, axis=1)\n",
    "    matrix_norms[matrix_norms == 0] = 1e-10\n",
    "\n",
    "    scores = matrix @ normalized_vector\n",
    "    return scores / matrix_norms\n",
    "\n",
    "\n",
    "def _chunk_text(text: str, chunk_size: int = 1200, overlap: int = 200):\n",
    "    \"\"\"Yield overlapping text windows for downstream embedding.\"\"\"\n",
    "    cleaned = \" \".join(text.split())\n",
    "    if not cleaned:\n",
    "        return\n",
    "    text_len = len(cleaned)\n",
    "    start = 0\n",
    "    while start < text_len:\n",
    "        end = min(text_len, start + chunk_size)\n",
    "        yield cleaned[start:end]\n",
    "        if end == text_len:\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "\n",
    "\n",
    "def _embed_texts_with_bedrock(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Call an AWS Bedrock embedding model and return dense vectors.\"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "\n",
    "    model_id = os.getenv(\"BEDROCK_EMBEDDING_MODEL_ID\", \"amazon.titan-embed-text-v2:0\")\n",
    "    region = os.getenv(\"AWS_DEFAULT_REGION\", \"us-west-2\")\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "\n",
    "    embeddings: List[List[float]] = []\n",
    "    for text in texts:\n",
    "        payload = json.dumps({\"inputText\": text})\n",
    "        try:\n",
    "            response = client.invoke_model(\n",
    "                body=payload,\n",
    "                modelId=model_id,\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\",\n",
    "            )\n",
    "        except (BotoCoreError, ClientError) as exc:\n",
    "            logger.error(\"Embedding request failed: %s\", exc)\n",
    "            raise RuntimeError(f\"Embedding request failed: {exc}\") from exc\n",
    "\n",
    "        body = response.get(\"body\")\n",
    "        data = json.loads(body.read()) if hasattr(body, \"read\") else json.loads(body)  # type: ignore[arg-type]\n",
    "        embedding = data.get(\"embedding\")\n",
    "        if not embedding:\n",
    "            raise RuntimeError(\"Embedding response missing 'embedding' field\")\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def ingest_pdf_folder(\n",
    "    folder_path: str = \"pdf_files\",\n",
    "    store_dir: Optional[str] = None,\n",
    "    batch_size: int = 16,\n",
    "    chunk_size: int = 1200,\n",
    "    chunk_overlap: int = 200,\n",
    ") -> str:\n",
    "    \"\"\"Ingest PDFs into the local numpy-based vector store.\"\"\"\n",
    "    source_dir = Path(folder_path)\n",
    "    if not source_dir.exists():\n",
    "        return f\"PDF folder '{folder_path}' not found. Skipping ingestion.\"\n",
    "\n",
    "    pdf_files = sorted(path for path in source_dir.iterdir() if path.suffix.lower() == \".pdf\")\n",
    "    if not pdf_files:\n",
    "        return f\"No PDF files discovered in '{folder_path}'.\"\n",
    "\n",
    "    vector_dir = _resolve_vector_store_dir(store_dir)\n",
    "\n",
    "    pending_records: List[dict] = []\n",
    "    staged_records: List[dict] = []\n",
    "    staged_embeddings: List[List[float]] = []\n",
    "\n",
    "    def flush_batch():\n",
    "        nonlocal pending_records\n",
    "        if not pending_records:\n",
    "            return\n",
    "        batch = pending_records\n",
    "        pending_records = []\n",
    "        texts = [record[\"text\"] for record in batch]\n",
    "        embeddings = _embed_texts_with_bedrock(texts)\n",
    "        staged_records.extend(batch)\n",
    "        staged_embeddings.extend(embeddings)\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        try:\n",
    "            reader = PdfReader(str(pdf_path))\n",
    "        except Exception as exc:  # pragma: no cover - depends on local files\n",
    "            logger.error(\"Failed to read %s: %s\", pdf_path, exc)\n",
    "            continue\n",
    "\n",
    "        for page_number, page in enumerate(reader.pages, start=1):\n",
    "            text = page.extract_text() or \"\"\n",
    "            for chunk_index, chunk in enumerate(_chunk_text(text, chunk_size, chunk_overlap), start=1):\n",
    "                snippet = chunk.strip()\n",
    "                if not snippet:\n",
    "                    continue\n",
    "                record_id = f\"pdf::{pdf_path.stem}::p{page_number}::c{chunk_index}::{uuid4().hex}\"\n",
    "                metadata = {\n",
    "                    \"source\": \"pdf\",\n",
    "                    \"file\": pdf_path.name,\n",
    "                    \"page\": page_number,\n",
    "                    \"chunk\": chunk_index,\n",
    "                }\n",
    "                pending_records.append({\"id\": record_id, \"text\": snippet, \"metadata\": metadata})\n",
    "                if len(pending_records) >= batch_size:\n",
    "                    flush_batch()\n",
    "\n",
    "    flush_batch()\n",
    "    added_chunks = _extend_vector_store(vector_dir, staged_embeddings, staged_records)\n",
    "    store_label = str(vector_dir)\n",
    "    return (\n",
    "        f\"Ingested {added_chunks} PDF chunks from {len(pdf_files)} files into vector store \"\n",
    "        f\"'{store_label}'.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _format_json(metadata):\n",
    "    \"\"\"Return metadata as a compact JSON string suitable for logging.\"\"\"\n",
    "    try:\n",
    "        return json.dumps(metadata, ensure_ascii=True)\n",
    "    except (TypeError, ValueError):\n",
    "        return str(metadata)\n",
    "\n",
    "\n",
    "# Tool implementations for the Cybersecurity RAG Agent\n",
    "# Tool: Mitre Attack Search\n",
    "@tool\n",
    "def mitre_attack_search(query: str) -> str:\n",
    "    \"\"\"Search the local numpy-based MITRE ATT&CK vector store for techniques and mitigations.\"\"\"\n",
    "    store_dir = _resolve_vector_store_dir()\n",
    "    top_k = int(os.getenv(\"MITRE_TOP_K\", \"3\"))\n",
    "\n",
    "    embeddings, records = _load_vector_store(store_dir)\n",
    "    if embeddings is None or not records:\n",
    "        return (\n",
    "            f\"Vector store '{store_dir}' is empty. Ingest MITRE or PDF data before searching.\"\n",
    "        )\n",
    "\n",
    "    query_embedding = _embed_texts_with_bedrock([query])[0]\n",
    "    query_vector = np.array(query_embedding, dtype=np.float32)\n",
    "\n",
    "    scores = _cosine_similarity_matrix(embeddings, query_vector)\n",
    "    if scores.size == 0:\n",
    "        return f\"No MITRE ATT&CK matches for '{query}'.\"\n",
    "\n",
    "    ranked_indices = np.argsort(scores)[::-1][:max(1, top_k)]\n",
    "\n",
    "    formatted = []\n",
    "    for rank, idx in enumerate(ranked_indices, start=1):\n",
    "        record = records[idx]\n",
    "        meta = record.get(\"metadata\", {})\n",
    "        snippet_text = (record.get(\"text\") or \"\").strip().replace(\"\\n\", \" \")\n",
    "        technique = meta.get(\"technique_id\") or meta.get(\"technique\") or \"Unknown Technique\"\n",
    "        tactic = meta.get(\"tactic\") or meta.get(\"phase_name\")\n",
    "        reference = meta.get(\"url\") or meta.get(\"reference\") or meta.get(\"file\")\n",
    "        similarity = f\"{scores[idx]:.4f}\"\n",
    "\n",
    "        formatted.append(\n",
    "            f\"{rank}. Technique: {technique}\"\n",
    "            f\"{' | Tactic: ' + tactic if tactic else ''}\\n\"\n",
    "            f\"   Cosine similarity: {similarity}\\n\"\n",
    "            f\"   Insight: {snippet_text[:600]}\\n\"\n",
    "            f\"   Reference: {reference or _format_json(meta)}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Tool: VirusTotal Lookup\n",
    "@tool\n",
    "def virustotal_lookup(query: str) -> str:\n",
    "    \"\"\"Query VirusTotal for malware, hashes, domains, or URLs related to the input.\"\"\"\n",
    "    api_key = os.getenv(\"VIRUSTOTAL_API_KEY\")\n",
    "    if not api_key:\n",
    "        return \"VirusTotal API key not configured. Set VIRUSTOTAL_API_KEY to enable this tool.\"\n",
    "\n",
    "    url = f\"https://www.virustotal.com/api/v3/search?query={quote_plus(query)}\"\n",
    "    headers = {\"x-apikey\": api_key}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as exc:  # pragma: no cover - network call\n",
    "        logger.error(\"VirusTotal lookup error: %s\", exc)\n",
    "        return f\"VirusTotal lookup error: {exc}\"\n",
    "\n",
    "    payload = response.json()\n",
    "    rows = payload.get(\"data\", [])\n",
    "    if not rows:\n",
    "        return f\"No VirusTotal matches found for '{query}'.\"\n",
    "\n",
    "    formatted = []\n",
    "    for idx, row in enumerate(rows[:5]):\n",
    "        attributes = row.get(\"attributes\", {})\n",
    "        stats = attributes.get(\"last_analysis_stats\", {})\n",
    "        total = sum(stats.values()) or 1\n",
    "        detection_ratio = f\"{stats.get('malicious', 0)}/{total}\"\n",
    "        threat_label = attributes.get(\"popular_threat_classification\", {}).get(\"suggested_threat_label\")\n",
    "        item_type = row.get(\"type\", \"unknown\")\n",
    "        vt_id = row.get(\"id\", \"unknown\")\n",
    "        gui_url = f\"https://www.virustotal.com/gui/{item_type}/{vt_id}\"\n",
    "\n",
    "        formatted.append(\n",
    "            f\"{idx + 1}. Type: {item_type} | Detection ratio: {detection_ratio}\\n\"\n",
    "            f\"   Threat label: {threat_label or 'Not classified'}\\n\"\n",
    "            f\"   VT link: {gui_url}\\n\"\n",
    "            f\"   Query context: {query}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Tool: NVD Vulnerability Search\n",
    "\n",
    "def _extract_cvss(metrics: dict) -> Tuple[str, str, str]:\n",
    "    \"\"\"Pick the most specific CVSS tuple (severity, score, vector) from NVD metrics.\"\"\"\n",
    "    metric_priority = (\"cvssMetricV31\", \"cvssMetricV30\", \"cvssMetricV2\")\n",
    "    for metric_name in metric_priority:\n",
    "        metric_entries = metrics.get(metric_name)\n",
    "        if metric_entries:\n",
    "            entry = metric_entries[0]\n",
    "            data = entry.get(\"cvssData\", {})\n",
    "            severity = entry.get(\"baseSeverity\") or data.get(\"baseSeverity\") or \"UNKNOWN\"\n",
    "            score = data.get(\"baseScore\") or entry.get(\"baseScore\") or \"N/A\"\n",
    "            vector = data.get(\"vectorString\") or \"N/A\"\n",
    "            return severity, str(score), vector\n",
    "    return \"UNKNOWN\", \"N/A\", \"N/A\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def nvd_vulnerability_search(query: str) -> str:\n",
    "    \"\"\"Search the National Vulnerability Database for CVEs related to the query.\"\"\"\n",
    "    params = {\n",
    "        \"keywordSearch\": query,\n",
    "        \"resultsPerPage\": os.getenv(\"NVD_RESULTS_PER_PAGE\", \"5\"),\n",
    "    }\n",
    "    headers = {}\n",
    "    api_key = os.getenv(\"NVD_API_KEY\")\n",
    "    if api_key:\n",
    "        headers[\"apiKey\"] = api_key\n",
    "\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://services.nvd.nist.gov/rest/json/cves/2.0\",\n",
    "            params=params,\n",
    "            headers=headers,\n",
    "            timeout=30,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as exc:  # pragma: no cover - network call\n",
    "        logger.error(\"NVD lookup error: %s\", exc)\n",
    "        return f\"NVD lookup error: {exc}\"\n",
    "\n",
    "    payload = response.json()\n",
    "    vulns = payload.get(\"vulnerabilities\", [])\n",
    "    if not vulns:\n",
    "        return f\"No NVD entries found for '{query}'.\"\n",
    "\n",
    "    formatted = []\n",
    "    for idx, item in enumerate(vulns[:5]):\n",
    "        cve = item.get(\"cve\", {})\n",
    "        cve_id = cve.get(\"id\", \"Unknown CVE\")\n",
    "        descriptions = cve.get(\"descriptions\", [])\n",
    "        description = next((d.get(\"value\") for d in descriptions if d.get(\"lang\") == \"en\"), \"No English description available.\")\n",
    "        metrics = cve.get(\"metrics\", {})\n",
    "        severity, score, vector = _extract_cvss(metrics)\n",
    "        published = cve.get(\"published\")\n",
    "\n",
    "        formatted.append(\n",
    "            f\"{idx + 1}. {cve_id}\\n\"\n",
    "            f\"   Severity: {severity} (score {score}, vector {vector})\\n\"\n",
    "            f\"   Published: {published or 'Unknown'}\\n\"\n",
    "            f\"   Summary: {description}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Bedrock LLM Model Initialization\n",
    "def get_bedrock_model():\n",
    "    \"\"\"Instantiate the configured Bedrock text model for conversational responses.\"\"\"\n",
    "    model_id = os.getenv(\"BEDROCK_MODEL_ID\", \"global.anthropic.claude-haiku-4-5-20251001-v1:0\")\n",
    "    region = os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\")\n",
    "\n",
    "    try:\n",
    "        bedrock_model = BedrockModel(\n",
    "            model_id=model_id,\n",
    "            region_name=region,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        logger.info(f\"Successfully initialized Bedrock model: {model_id} in region: {region}\")\n",
    "        return bedrock_model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Bedrock model: {str(e)}\")\n",
    "        logger.error(\"Please ensure you have proper AWS credentials configured and access to the Bedrock model\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point that ingests data, configures telemetry, and runs the agent.\"\"\"\n",
    "    # Parse command line arguments\n",
    "    args = parse_arguments()\n",
    "    s3_handler = configure_s3_log_archival(args.session_id)\n",
    "\n",
    "    # Set session context for telemetry\n",
    "    context_token = set_session_context(args.session_id)\n",
    "\n",
    "    try:\n",
    "        # Optionally ingest PDFs before initializing the conversational model\n",
    "        ingest_summary = None\n",
    "        if args.ingest_pdfs:\n",
    "            try:\n",
    "                ingest_summary = ingest_pdf_folder(folder_path=args.pdf_folder)\n",
    "                logger.info(ingest_summary)\n",
    "            except Exception as exc:  # pragma: no cover - depends on local data\n",
    "                logger.error(\"PDF ingestion failed: %s\", exc)\n",
    "                ingest_summary = f\"PDF ingestion failed: {exc}\"\n",
    "\n",
    "        # Initialize Bedrock model\n",
    "        bedrock_model = get_bedrock_model()\n",
    "\n",
    "        # Create cybersecurity agent\n",
    "        cybersecurity_agent = Agent(\n",
    "            model=bedrock_model,\n",
    "            system_prompt=\"\"\"You are a Cybersecurity Expert that helps analyst questions, selects the most relevant \n",
    "            data source, and synthesizes a concise incident response report. Use the MITRE ATT&CK tool for questions \n",
    "            about adversary behavior or attack techniques, the VirusTotal tool for malware, hashes, or domains, and the \n",
    "            NVD tool for software vulnerabilities or CVE lookups. Always explain which source you used and cite key \n",
    "            evidence.\"\"\",\n",
    "            tools=[mitre_attack_search, virustotal_lookup, nvd_vulnerability_search],\n",
    "            trace_attributes={\n",
    "                \"user.id\": \"user@domain.com\",\n",
    "                \"tags\": [\"Strands\", \"Cybersecurity\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # # Execute the cybersecurity investigation\n",
    "        # query = args.question or \"\"\"What is the MITRE ATT&CK technique for brute forcing RDP, and are there any known vulnerabilities\"\"\"\n",
    "\n",
    "        # result = cybersecurity_agent(query)\n",
    "        # if ingest_summary:\n",
    "        #     print(\"PDF ingestion:\", ingest_summary)\n",
    "        # print(\"Result:\", result)\n",
    "\n",
    "    finally:\n",
    "        # Detach context when done\n",
    "        context.detach(context_token)\n",
    "        logger.info(f\"Session context for '{args.session_id}' detached\")\n",
    "        if s3_handler:\n",
    "            s3_handler.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AWS OpenTelemetry Python Distro\n",
    "\n",
    "<span style=\"font-size:18px;\"> Now that the agent is setup and environment is configured, let's understand how the observability happens.</span>  \n",
    "   \n",
    "<span style=\"font-size:18px;\"> The [AWS OpenTelemetry Python Distro](https://pypi.org/project/aws-opentelemetry-distro/) automatically instruments the Strands agent to capture telemetry data without requiring code changes.</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\">The distribution provides:</span>  \n",
    "- <span style=\"font-size:18px;\"> **Auto-instrumentation** for your Strands Agent hosted outside of AgentCore Runtime (i.e. EC2, Lambda etc..)</span>  \n",
    "- <span style=\"font-size:18px;\">**AWS-optimized configuration** for seamless CloudWatch integration</span>    \n",
    "\n",
    "### Running Your Instrumented Agent\n",
    "\n",
    "<span style=\"font-size:18px;\"> To capture traces from your Strands agent, use the `opentelemetry-instrument` command instead of running Python directly.</span>  \n",
    "\n",
    "```bash\n",
    "opentelemetry-instrument python cyberwizard_rag_agent.py\n",
    "```\n",
    "\n",
    "<span style=\"font-size:18px;\">This automatically applies instrumentation using the environment variables from the `.env` file.</span>\n",
    "\n",
    "<span style=\"font-size:18px;\">This command will:</span>\n",
    "\n",
    "- <span style=\"font-size:18px;\">Load your OTEL configuration from the .env file.</span>\n",
    "  \n",
    "- <span style=\"font-size:18px;\">Automatically instrument Strands, Amazon Bedrock calls, agent tool and databases, and other requests made by agent.</span>\n",
    "  \n",
    "- <span style=\"font-size:18px;\">Send traces to CloudWatch.</span>\n",
    "  \n",
    "- <span style=\"font-size:18px;\">Enable you to visualize the agent's decision-making process in the GenAI Observability dashboard.</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
      "INFO:__main__:AWS X-Ray tracing configured (region=us-east-1, service=strands-cyber-rag, sample_ratio=1.0)\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:__main__:S3 log archival enabled (bucket=cyberwizard-rag-agent, prefix=cloudwatch-export)\n",
      "INFO:root:Session ID '1100' attached to telemetry context\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:__main__:Successfully initialized Bedrock model: global.anthropic.claude-haiku-4-5-20251001-v1:0 in region: us-east-1\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:strands.telemetry.metrics:Creating Strands MetricsClient\n",
      "\n",
      "Tool #1: mitre_attack_search\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "Based on the MITRE ATT&CK framework, the main technique used for brute force attacks is **T1110 - Brute Force**.\n",
      "\n",
      "## Key Details:\n",
      "\n",
      "**Technique Name:** Brute Force (T1110)\n",
      "\n",
      "**Definition:** Adversaries use brute force techniques to gain access to accounts when passwords are unknown or when password hashes have been obtained.\n",
      "\n",
      "**How It Works:**\n",
      "- Adversaries systematically guess passwords using a repetitive orINFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      " iterative mechanism\n",
      "- Can occur through:\n",
      "  - **Online:** Direct interaction with a service that validates credentials (e.g., login portals)\n",
      "  - **Offline:** Against previously acquired credential data, such as password hashes\n",
      "\n",
      "**Common Scenarios:**\n",
      "- Without knowledge of a password for an account or set of accounts, attackers will try multiple password combinations\n",
      "- Often used after credential dumping or data breaches where password hashes are obtained\n",
      "- Can target various services including web applications, remote access systems, and authentication platforms\n",
      "\n",
      "**Related Techniques:**\n",
      "- **T1110.001 - Password Guessing:** Trying common or predictable passwords\n",
      "- **T1110.002 - Password Spraying:** Using a few common passwords across many accounts\n",
      "- **T1110.003 - Password Cracking:** Attempting to crack obtained password hashes\n",
      "- **T1110.004 - Credential Stuffing:** Using previously compromised credentials on other systems\n",
      "\n",
      "This is a fundamental attack technique used across many threat campaigns and remains effective, especially against weak or reused passwords.Result: Based on the MITRE ATT&CK framework, the main technique used for brute force attacks is **T1110 - Brute Force**.\n",
      "\n",
      "## Key Details:\n",
      "\n",
      "**Technique Name:** Brute Force (T1110)\n",
      "\n",
      "**Definition:** Adversaries use brute force techniques to gain access to accounts when passwords are unknown or when password hashes have been obtained.\n",
      "\n",
      "**How It Works:**\n",
      "- Adversaries systematically guess passwords using a repetitive or iterative mechanism\n",
      "- Can occur through:\n",
      "  - **Online:** Direct interaction with a service that validates credentials (e.g., login portals)\n",
      "  - **Offline:** Against previously acquired credential data, such as password hashes\n",
      "\n",
      "**Common Scenarios:**\n",
      "- Without knowledge of a password for an account or set of accounts, attackers will try multiple password combinations\n",
      "- Often used after credential dumping or data breaches where password hashes are obtained\n",
      "- Can target various services including web applications, remote access systems, and authentication platforms\n",
      "\n",
      "**Related Techniques:**\n",
      "- **T1110.001 - Password Guessing:** Trying common or predictable passwords\n",
      "- **T1110.002 - Password Spraying:** Using a few common passwords across many accounts\n",
      "- **T1110.003 - Password Cracking:** Attempting to crack obtained password hashes\n",
      "- **T1110.004 - Credential Stuffing:** Using previously compromised credentials on other systems\n",
      "\n",
      "This is a fundamental attack technique used across many threat campaigns and remains effective, especially against weak or reused passwords.\n",
      "\n",
      "INFO:__main__:Session context for '1100' detached\n",
      "/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py:153: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "[S3LogHandler] Uploaded logs to s3://cyberwizard-rag-agent/cloudwatch-export/2026/01/28/1100-032813-b66d88933b99497090dc97dee94826b8-0001.log\n",
      "Exception ignored in atexit callback <bound method S3LogHandler.close of <S3LogHandler (INFO)>>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 132, in close\n",
      "    self.flush()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 125, in flush\n",
      "    payload = self._drain_buffer_locked()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 142, in _drain_buffer_locked\n",
      "    contents = self._buffer.getvalue()\n",
      "ValueError: I/O operation on closed file\n"
     ]
    }
   ],
   "source": [
    "!opentelemetry-instrument python cyberwizard_rag_agent.py --session-id 1100 --question \"What is the main technique used for bruteforce attack?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
      "INFO:__main__:AWS X-Ray tracing configured (region=us-east-1, service=strands-cyber-rag, sample_ratio=1.0)\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:__main__:S3 log archival enabled (bucket=cyberwizard-rag-agent, prefix=cloudwatch-export)\n",
      "INFO:root:Session ID '1100' attached to telemetry context\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:__main__:Successfully initialized Bedrock model: global.anthropic.claude-haiku-4-5-20251001-v1:0 in region: us-east-1\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:strands.telemetry.metrics:Creating Strands MetricsClient\n",
      "I'll check that file hash on VirusTotal for you.\n",
      "Tool #1: virustotal_lookup\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "## VirusTotal Lookup Result\n",
      "\n",
      "**Hash:** 44d88612fea8a8f36de82e1278abb02f\n",
      "\n",
      "**Status:**  **FLAGGED AS MALICIOUS**\n",
      "\n",
      "**Key Findings:**\n",
      "- **Detection Ratio:** 55 out of 76 antivirus engines flagged this file\n",
      "- **Threat Label:** `virus.eicar/test`\n",
      "- **VirusTotal Link:** https://www.virustotal.com/gui/file/275a021bbfb6489e54d471899f7db9d1663fc695ec2fe2a2c4538aabf651fd0f\n",
      "\n",
      "**Analysis:**\n",
      "This hash is associated with the **EICAR test file**, which is a standard test file used by the antivirus and cybersecurity community to verify that security software is functioning correctly. The EICAR file is **not actually malicious** in the traditional senseit's a harmless test string designed to trigger antivirus alerts intentionally.\n",
      "\n",
      "**Recommendation:**\n",
      "- If this file was found on a system in a legitimate testing context (e.g., antivirus testing), it is **safe and expected**.\n",
      "- If this file appeared unexpectedly on a production system, investigate the source and context of how it arrived.\n",
      "- This is likely a **false positive** in a real-world incident unless someone was specifically testing security controls.\n",
      "\n",
      "Would you like me to investigate any other indicators or provide additional context?Result: ## VirusTotal Lookup Result\n",
      "\n",
      "**Hash:** 44d88612fea8a8f36de82e1278abb02f\n",
      "\n",
      "**Status:**  **FLAGGED AS MALICIOUS**\n",
      "\n",
      "**Key Findings:**\n",
      "- **Detection Ratio:** 55 out of 76 antivirus engines flagged this file\n",
      "- **Threat Label:** `virus.eicar/test`\n",
      "- **VirusTotal Link:** https://www.virustotal.com/gui/file/275a021bbfb6489e54d471899f7db9d1663fc695ec2fe2a2c4538aabf651fd0f\n",
      "\n",
      "**Analysis:**\n",
      "This hash is associated with the **EICAR test file**, which is a standard test file used by the antivirus and cybersecurity community to verify that security software is functioning correctly. The EICAR file is **not actually malicious** in the traditional senseit's a harmless test string designed to trigger antivirus alerts intentionally.\n",
      "\n",
      "**Recommendation:**\n",
      "- If this file was found on a system in a legitimate testing context (e.g., antivirus testing), it is **safe and expected**.\n",
      "- If this file appeared unexpectedly on a production system, investigate the source and context of how it arrived.\n",
      "- This is likely a **false positive** in a real-world incident unless someone was specifically testing security controls.\n",
      "\n",
      "Would you like me to investigate any other indicators or provide additional context?\n",
      "\n",
      "INFO:__main__:Session context for '1100' detached\n",
      "/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py:153: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "[S3LogHandler] Uploaded logs to s3://cyberwizard-rag-agent/cloudwatch-export/2026/01/28/1100-151356-cd6d4dbcb67e4354b8e64981ebcf73a7-0001.log\n",
      "Exception ignored in atexit callback <bound method S3LogHandler.close of <S3LogHandler (INFO)>>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 132, in close\n",
      "    self.flush()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 125, in flush\n",
      "    payload = self._drain_buffer_locked()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 142, in _drain_buffer_locked\n",
      "    contents = self._buffer.getvalue()\n",
      "ValueError: I/O operation on closed file\n"
     ]
    }
   ],
   "source": [
    "!opentelemetry-instrument python cyberwizard_rag_agent.py --session-id 1100 --question \"Can you check this file hash on VirusTotal and tell me if its malicious? The hash is 44d88612fea8a8f36de82e1278abb02f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
      "INFO:__main__:AWS X-Ray tracing configured (region=us-east-1, service=strands-cyber-rag, sample_ratio=1.0)\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:__main__:S3 log archival enabled (bucket=cyberwizard-rag-agent, prefix=cloudwatch-export)\n",
      "INFO:root:Session ID '1100' attached to telemetry context\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:__main__:Successfully initialized Bedrock model: global.anthropic.claude-haiku-4-5-20251001-v1:0 in region: us-east-1\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "INFO:strands.telemetry.metrics:Creating Strands MetricsClient\n",
      "\n",
      "Tool #1: nvd_vulnerability_search\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "## CVE-2021-44228 CVSS Severity Report\n",
      "\n",
      "**Source:** National Vulnerability Database (NVD)\n",
      "\n",
      "### Key Findings:\n",
      "\n",
      "**CVE-2021-44228 Severity: CRITICAL**\n",
      "- **CVSS Score:** 10.0 (Maximum severity)\n",
      "- **CVSS Vector:** CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\n",
      "- **Published:** December 10, 2021\n",
      "\n",
      "### Vulnerability Details:\n",
      "\n",
      "This is the infamous **Log4j2 Remote Code Execution (RCE)** vulnerability affecting Apache Log4j2 versions 2.0-beta9 through 2.15.0. The vulnerability exploits JNDI (Java Naming and Directory Interface) features that allow attackers to:\n",
      "\n",
      "- **Execute arbitrary code** by controlling log messages or log message parameters\n",
      "- **Load malicious code from LDAP servers** when message lookup substitution is enabled\n",
      "- Requires **no authentication or user interaction** (PR:N, UI:N)\n",
      "- Has **network-based attack vector** (AV:N)\n",
      "\n",
      "### Impact Scope:\n",
      "- **Confidentiality:** High (C:H)\n",
      "- **Integrity:** High (I:H)\n",
      "- **Availability:** High (A:H)\n",
      "- **Scope:** Changed (S:C)  affects resources beyond the vulnerable component\n",
      "\n",
      "This vulnerability is one of the most critical security issues in recent years and affected millions of applications worldwide.Result: ## CVE-2021-44228 CVSS Severity Report\n",
      "\n",
      "**Source:** National Vulnerability Database (NVD)\n",
      "\n",
      "### Key Findings:\n",
      "\n",
      "**CVE-2021-44228 Severity: CRITICAL**\n",
      "- **CVSS Score:** 10.0 (Maximum severity)\n",
      "- **CVSS Vector:** CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\n",
      "- **Published:** December 10, 2021\n",
      "\n",
      "### Vulnerability Details:\n",
      "\n",
      "This is the infamous **Log4j2 Remote Code Execution (RCE)** vulnerability affecting Apache Log4j2 versions 2.0-beta9 through 2.15.0. The vulnerability exploits JNDI (Java Naming and Directory Interface) features that allow attackers to:\n",
      "\n",
      "- **Execute arbitrary code** by controlling log messages or log message parameters\n",
      "- **Load malicious code from LDAP servers** when message lookup substitution is enabled\n",
      "- Requires **no authentication or user interaction** (PR:N, UI:N)\n",
      "- Has **network-based attack vector** (AV:N)\n",
      "\n",
      "### Impact Scope:\n",
      "- **Confidentiality:** High (C:H)\n",
      "- **Integrity:** High (I:H)\n",
      "- **Availability:** High (A:H)\n",
      "- **Scope:** Changed (S:C)  affects resources beyond the vulnerable component\n",
      "\n",
      "This vulnerability is one of the most critical security issues in recent years and affected millions of applications worldwide.\n",
      "\n",
      "INFO:__main__:Session context for '1100' detached\n",
      "/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py:153: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n",
      "[S3LogHandler] Uploaded logs to s3://cyberwizard-rag-agent/cloudwatch-export/2026/01/28/1100-151751-cf39bd2b0df24957b3afede61d7c0f90-0001.log\n",
      "Exception ignored in atexit callback <bound method S3LogHandler.close of <S3LogHandler (INFO)>>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 132, in close\n",
      "    self.flush()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 125, in flush\n",
      "    payload = self._drain_buffer_locked()\n",
      "  File \"/Users/harikoduvely/Projects/Courses/Course-Evaluation-of-GenAI-Applications/Session-3-Practical-Use-Case-Evaluations/cyberwizard_rag_agent.py\", line 142, in _drain_buffer_locked\n",
      "    contents = self._buffer.getvalue()\n",
      "ValueError: I/O operation on closed file\n"
     ]
    }
   ],
   "source": [
    "!opentelemetry-instrument python cyberwizard_rag_agent.py --session-id 1100 --question \"Query the NVD database for the CVSS severity of CVE202144228\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gen AI Observability Dashboard Understanding the Traces in AWS CloudWatch\n",
    "\n",
    "<span style=\"font-size:18px;\">Once the Strands agent runs with OpenTelemetry instrumentation, one can visualize and analyze the traces in AWS CloudWatch dashboard.</span> \n",
    "\n",
    "Navigate to Bedrock Agentcore and click on the Agent you just created.\n",
    "\n",
    "#### OverView Page:\n",
    "\n",
    "![image.png](../Images/cloudwatch-1.png)\n",
    "\n",
    "\n",
    "#### Trace View Page:\n",
    "Trace View:\n",
    "\n",
    "![image.png](../Images/cloudwatch-2.png)\n",
    "\n",
    "\n",
    "Trace details:\n",
    "\n",
    "![image.png](../Images/cloudwatch-3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation of the results using Judge-LLM  \n",
    "\n",
    "<span style=\"font-size:18px;\">Here we set up an evaluation pipeline using **DeepEval** framework which will:</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Extract the agent response and tools used from CloudWatch observability data.</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">If the query involves searching the MITRE ATT&CK knowledgebase:</span>  \n",
    "\n",
    "    - <span style=\"font-size:18px;\">Evaluate the Correctness of the Tool Call.</span>  \n",
    "\n",
    "    - <span style=\"font-size:18px;\">Evaluate the result using the RAGAS Metrics Faithfulness, Context Relevance and Answer Relevance.</span>   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../Images/deepeval-ragas-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../Images/deepeval-tooluse-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing llm_as_a_judge_evaluator_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile llm_as_a_judge_evaluator_agent.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Set, Tuple\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    from tabulate import tabulate\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    tabulate = None\n",
    "\n",
    "from deepeval.metrics import (\n",
    "    AnswerRelevancyMetric,\n",
    "    ContextualRelevancyMetric,\n",
    "    FaithfulnessMetric,\n",
    "    ToolUseMetric\n",
    ")\n",
    "\n",
    "try:\n",
    "    from deepeval import evaluate as deepeval_evaluate\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    deepeval_evaluate = None\n",
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.test_case.conversational_test_case import Turn\n",
    "from deepeval.test_case.llm_test_case import ToolCall\n",
    "\n",
    "SKIP_TEXT_KEYS = {\"toolUseId\", \"status\", \"role\", \"finish_reason\", \"id\", \"name\"}\n",
    "CaseBundle = Tuple[str, LLMTestCase, Dict[str, object], ConversationalTestCase]\n",
    "\n",
    "\n",
    "def _iter_table_objects(log_path: Path) -> Iterable[Dict]:\n",
    "    \"\"\"Yield OTEL log dicts parsed from CloudWatch table exports.\"\"\"\n",
    "    decoder = json.JSONDecoder()\n",
    "    text = log_path.read_text(encoding=\"utf-8\")\n",
    "    length = len(text)\n",
    "    idx = 0\n",
    "    while idx < length:\n",
    "        brace = text.find(\"{\", idx)\n",
    "        if brace == -1:\n",
    "            break\n",
    "        try:\n",
    "            payload, end = decoder.raw_decode(text, brace)\n",
    "        except json.JSONDecodeError:\n",
    "            idx = brace + 1\n",
    "            continue\n",
    "        if isinstance(payload, dict) and \"resource\" in payload and \"timeUnixNano\" in payload:\n",
    "            yield payload\n",
    "            idx = end\n",
    "        else:\n",
    "            idx = brace + 1\n",
    "\n",
    "\n",
    "def iter_log_objects(log_path: Path) -> Iterable[Dict]:\n",
    "    \"\"\"Iterate JSON log objects from a trace file with table fallback.\"\"\"\n",
    "    text = log_path.read_text(encoding=\"utf-8\")\n",
    "    try:\n",
    "        payload = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        yield from _iter_table_objects(log_path)\n",
    "        return\n",
    "\n",
    "    if isinstance(payload, list):\n",
    "        for item in payload:\n",
    "            if isinstance(item, dict):\n",
    "                yield item\n",
    "    elif isinstance(payload, dict):\n",
    "        yield payload\n",
    "\n",
    "\n",
    "def extract_texts(node) -> List[str]:\n",
    "    \"\"\"Collect unique text snippets from nested payload structures.\"\"\"\n",
    "    seen: Set[str] = set()\n",
    "    texts: List[str] = []\n",
    "\n",
    "    def _walk(value, key_hint: str | None = None) -> None:\n",
    "        if isinstance(value, str):\n",
    "            stripped = value.strip()\n",
    "            if not stripped or key_hint in SKIP_TEXT_KEYS:\n",
    "                return\n",
    "            if stripped.startswith((\"{\", \"[\")):\n",
    "                try:\n",
    "                    parsed = json.loads(stripped)\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "                else:\n",
    "                    _walk(parsed, key_hint)\n",
    "                    return\n",
    "            if stripped not in seen:\n",
    "                seen.add(stripped)\n",
    "                texts.append(stripped)\n",
    "        elif isinstance(value, dict):\n",
    "            for key, child in value.items():\n",
    "                if key in SKIP_TEXT_KEYS:\n",
    "                    continue\n",
    "                _walk(child, key)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                _walk(item, key_hint)\n",
    "\n",
    "    _walk(node)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def extract_tool_names(node) -> Set[str]:\n",
    "    \"\"\"Collect tool names referenced within nested payloads.\"\"\"\n",
    "    names: Set[str] = set()\n",
    "\n",
    "    def _walk(value) -> None:\n",
    "        if isinstance(value, dict):\n",
    "            if \"toolUse\" in value and isinstance(value[\"toolUse\"], dict):\n",
    "                maybe = value[\"toolUse\"].get(\"name\")\n",
    "                if isinstance(maybe, str) and maybe:\n",
    "                    names.add(maybe)\n",
    "            if \"function\" in value and isinstance(value[\"function\"], dict):\n",
    "                maybe = value[\"function\"].get(\"name\")\n",
    "                if isinstance(maybe, str) and maybe:\n",
    "                    names.add(maybe)\n",
    "            if \"name\" in value and any(k in value for k in {\"arguments\", \"input_parameters\"}):\n",
    "                maybe = value.get(\"name\")\n",
    "                if isinstance(maybe, str) and maybe:\n",
    "                    names.add(maybe)\n",
    "            for child in value.values():\n",
    "                _walk(child)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                _walk(item)\n",
    "\n",
    "    _walk(node)\n",
    "    return names\n",
    "\n",
    "\n",
    "def _ingest_strands_tracer_event(details: Dict[str, object], body: Dict) -> None:\n",
    "    \"\"\"Merge strands telemetry tracer messages into trace details.\"\"\"\n",
    "    messages = body.get(\"input\", {}).get(\"messages\", [])\n",
    "    for message in messages:\n",
    "        role = message.get(\"role\")\n",
    "        texts = extract_texts(message)\n",
    "        if role == \"user\" and texts:\n",
    "            if not details[\"user\"]:\n",
    "                details[\"user\"] = texts[0]\n",
    "        elif role == \"tool\":\n",
    "            for ctx in texts:\n",
    "                if ctx not in details[\"contexts\"]:\n",
    "                    details[\"contexts\"].append(ctx)\n",
    "        details[\"tool_names\"].update(extract_tool_names(message))\n",
    "\n",
    "    outputs = body.get(\"output\", {}).get(\"messages\", [])\n",
    "    for message in outputs:\n",
    "        role = message.get(\"role\")\n",
    "        texts = extract_texts(message)\n",
    "        if role == \"assistant\" and texts:\n",
    "            details[\"answer\"] = texts[-1]\n",
    "        elif role == \"tool\":\n",
    "            for ctx in texts:\n",
    "                if ctx not in details[\"contexts\"]:\n",
    "                    details[\"contexts\"].append(ctx)\n",
    "        details[\"tool_names\"].update(extract_tool_names(message))\n",
    "\n",
    "\n",
    "def collect_trace_data(log_path: Path) -> Dict[str, Dict[str, object]]:\n",
    "    \"\"\"Aggregate trace entries into user, answer, context, and tool data.\"\"\"\n",
    "    traces: Dict[str, Dict[str, object]] = defaultdict(\n",
    "        lambda: {\n",
    "            \"user\": None,\n",
    "            \"answer\": None,\n",
    "            \"contexts\": [],\n",
    "            \"tool_names\": set(),\n",
    "            \"source_files\": {log_path.name},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for entry in iter_log_objects(log_path):\n",
    "        trace_id = entry.get(\"traceId\") or entry.get(\"attributes\", {}).get(\"otelTraceID\")\n",
    "        if not trace_id or trace_id in {\"0\", \"\"}:\n",
    "            continue\n",
    "        event_name = entry.get(\"attributes\", {}).get(\"event.name\")\n",
    "        body = entry.get(\"body\")\n",
    "        details = traces[trace_id]\n",
    "        details[\"source_files\"].add(log_path.name)\n",
    "        if event_name == \"gen_ai.user.message\":\n",
    "            texts = extract_texts(body)\n",
    "            if texts and not details[\"user\"]:\n",
    "                details[\"user\"] = texts[0]\n",
    "        elif event_name == \"gen_ai.choice\":\n",
    "            texts = extract_texts(body)\n",
    "            if texts:\n",
    "                details[\"answer\"] = texts[-1]\n",
    "        elif event_name == \"gen_ai.assistant.message\":\n",
    "            texts = extract_texts(body)\n",
    "            if texts:\n",
    "                details[\"answer\"] = texts[-1]\n",
    "        elif event_name == \"gen_ai.tool.message\":\n",
    "            for ctx in extract_texts(body):\n",
    "                if ctx not in details[\"contexts\"]:\n",
    "                    details[\"contexts\"].append(ctx)\n",
    "        elif event_name == \"strands.telemetry.tracer\" and isinstance(body, dict):\n",
    "            _ingest_strands_tracer_event(details, body)\n",
    "        if body:\n",
    "            details[\"tool_names\"].update(extract_tool_names(body))\n",
    "\n",
    "    return traces\n",
    "\n",
    "\n",
    "def build_cases(log_path: Path) -> List[CaseBundle]:\n",
    "    \"\"\"Construct DeepEval test cases from collected trace data.\"\"\"\n",
    "    traces = collect_trace_data(log_path)\n",
    "    bundles: List[CaseBundle] = []\n",
    "    for trace_id, info in traces.items():\n",
    "        if not info[\"user\"] or not info[\"answer\"]:\n",
    "            continue\n",
    "        retrieval_context = info[\"contexts\"] or []\n",
    "        tool_calls = [ToolCall(name=name) for name in sorted(info[\"tool_names\"])]\n",
    "        case = LLMTestCase(\n",
    "            input=info[\"user\"],\n",
    "            actual_output=info[\"answer\"],\n",
    "            retrieval_context=retrieval_context,\n",
    "            tools_called=tool_calls,\n",
    "            additional_metadata={\n",
    "                \"trace_id\": trace_id,\n",
    "                \"source_files\": sorted(info[\"source_files\"]),\n",
    "            },\n",
    "        )\n",
    "        # Tool correctness metrics require an expected tool plan; default to observed tools.\n",
    "        case.expected_tools = tool_calls  # type: ignore[attr-defined]\n",
    "\n",
    "        turns = [\n",
    "            Turn(role=\"user\", content=info[\"user\"], retrieval_context=retrieval_context or None),\n",
    "            Turn(\n",
    "                role=\"assistant\",\n",
    "                content=info[\"answer\"],\n",
    "                tools_called=tool_calls or None,\n",
    "                retrieval_context=retrieval_context or None,\n",
    "            ),\n",
    "        ]\n",
    "        conversational_case = ConversationalTestCase(\n",
    "            turns=turns,\n",
    "            context=retrieval_context or None,\n",
    "            additional_metadata={\n",
    "                \"trace_id\": trace_id,\n",
    "                \"source_files\": sorted(info[\"source_files\"]),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        bundles.append((trace_id, case, info, conversational_case))\n",
    "    return bundles\n",
    "\n",
    "\n",
    "def evaluate_rag(cases: List[CaseBundle]) -> None:\n",
    "    \"\"\"Measure RAG quality metrics for the provided cases.\"\"\"\n",
    "    eval_model_name = os.getenv(\"DEEPEVAL_MODEL_NAME\", \"gpt-4o-mini\")\n",
    "    metrics = [\n",
    "        (\"Faithfulness\", FaithfulnessMetric(model=eval_model_name)),\n",
    "        (\"Answer Relevance\", AnswerRelevancyMetric(model=eval_model_name)),\n",
    "        (\"Context Relevance\", ContextualRelevancyMetric(model=eval_model_name)),\n",
    "    ]\n",
    "    rows = []\n",
    "    for trace_id, case, info, _ in cases:\n",
    "        row = {\n",
    "            \"trace\": trace_id[:8],\n",
    "            \"tools\": \", \".join(sorted(info[\"tool_names\"])) or \"None\",\n",
    "            \"contexts\": len(info[\"contexts\"]),\n",
    "        }\n",
    "        for label, metric in metrics:\n",
    "            try:\n",
    "                score = metric.measure(case, _show_indicator=False)\n",
    "            except Exception as exc:  # pragma: no cover - network / LLM issues\n",
    "                score = float(\"nan\")\n",
    "                print(f\"[WARN] {label} failed for trace {trace_id}: {exc}\")\n",
    "            row[label] = score\n",
    "        rows.append(row)\n",
    "    if tabulate:\n",
    "        print(tabulate(rows, headers=\"keys\", floatfmt=\".3f\"))\n",
    "    else:\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "\n",
    "\n",
    "def evaluate_tool_usage(cases: List[CaseBundle]) -> None:\n",
    "    \"\"\"Summarize tool usage and score it with the ToolUseMetric.\"\"\"\n",
    "    tool_use_metric = None\n",
    "    if ToolUseMetric:\n",
    "        try:\n",
    "            threshold = float(os.getenv(\"TOOL_USE_THRESHOLD\", \"0.5\"))\n",
    "        except ValueError:\n",
    "            threshold = 0.5\n",
    "        available_tools_env = os.getenv(\"TOOL_USE_AVAILABLE_TOOLS\")\n",
    "        if available_tools_env:\n",
    "            available_tools = [name.strip() for name in available_tools_env.split(\",\") if name.strip()]\n",
    "        else:\n",
    "            available_tools = [\n",
    "                \"mitre_attack_search\",\n",
    "                \"virustotal_lookup\",\n",
    "                \"nvd_vulnerability_search\",\n",
    "            ]\n",
    "        tool_use_metric = ToolUseMetric(\n",
    "            available_tools=available_tools,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    else:\n",
    "        print(\"[INFO] ToolUseMetric unavailable; install deepeval with agentic extras\")\n",
    "\n",
    "    rows = []\n",
    "    tool_frequency: Dict[str, int] = defaultdict(int)\n",
    "    conversational_cases = []\n",
    "    for trace_id, case, info, conv_case in cases:\n",
    "        names = sorted(info[\"tool_names\"])\n",
    "        for name in names:\n",
    "            tool_frequency[name] += 1\n",
    "        row = {\n",
    "            \"trace\": trace_id[:8],\n",
    "            \"tool_count\": len(names),\n",
    "            \"tools\": \", \".join(names) or \"None\",\n",
    "        }\n",
    "        if tool_use_metric:\n",
    "            conversational_cases.append(conv_case)\n",
    "            try:\n",
    "                row[\"Tool Use\"] = tool_use_metric.measure(conv_case, _show_indicator=False)\n",
    "            except Exception as exc:  # pragma: no cover - LLM/network failures\n",
    "                row[\"Tool Use\"] = float(\"nan\")\n",
    "                print(f\"[WARN] Tool Use metric failed for trace {trace_id}: {exc}\")\n",
    "        rows.append(row)\n",
    "\n",
    "    if tabulate:\n",
    "        print(tabulate(rows, headers=\"keys\", floatfmt=\".3f\"))\n",
    "    else:\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "\n",
    "    if tool_frequency:\n",
    "        print(\"\\nAggregated tool usage:\")\n",
    "        for name, count in sorted(tool_frequency.items(), key=lambda item: (-item[1], item[0])):\n",
    "            print(f\"- {name}: {count} trace(s)\")\n",
    "    else:\n",
    "        print(\"\\nNo tool usage captured in the provided trace data.\")\n",
    "\n",
    "    if tool_use_metric and deepeval_evaluate and conversational_cases:\n",
    "        try:\n",
    "            deepeval_evaluate(\n",
    "                test_cases=conversational_cases,\n",
    "                metrics=[tool_use_metric],\n",
    "                show_indicator=False,\n",
    "            )\n",
    "        except TypeError:\n",
    "            # Older deepeval versions may not support keyword args.\n",
    "            try:\n",
    "                deepeval_evaluate(conversational_cases, [tool_use_metric])\n",
    "            except Exception as exc:  # pragma: no cover\n",
    "                print(f\"[WARN] Unable to run deepeval.evaluate: {exc}\")\n",
    "        except Exception as exc:  # pragma: no cover - network/LLM issues\n",
    "            print(f\"[WARN] ToolUseMetric evaluation failed: {exc}\")\n",
    "    elif tool_use_metric and not conversational_cases:\n",
    "        print(\"[INFO] No conversational test cases available for ToolUseMetric evaluation.\")\n",
    "    elif tool_use_metric:\n",
    "        print(\"[INFO] deepeval.evaluate not available; skipped evaluator run\")\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    \"\"\"Parse CLI arguments for the evaluator script.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Evaluate Strands agent traces using DeepEval metrics.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"log_path\",\n",
    "        help=\"Path to the OTEL trace log file (JSON or CloudWatch table export).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"mode\",\n",
    "        choices=[\"rag\", \"tool\"],\n",
    "        help=\"Select 'rag' for RAG quality metrics or 'tool' for tool usage summaries.\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Entrypoint that loads configuration and runs the selected evaluation.\"\"\"\n",
    "    load_dotenv(override=False)\n",
    "    args = parse_args()\n",
    "    log_path = Path(args.log_path).expanduser()\n",
    "    if not log_path.exists():\n",
    "        raise FileNotFoundError(f\"Trace file not found: {log_path}\")\n",
    "    cases = build_cases(log_path)\n",
    "    if not cases:\n",
    "        print(\"No completed traces found to evaluate.\")\n",
    "        return\n",
    "    if args.mode == \"rag\":\n",
    "        evaluate_rag(cases)\n",
    "    else:\n",
    "        evaluate_tool_usage(cases)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace     tools                  contexts    Faithfulness    Answer Relevance    Context Relevance\n",
      "--------  -------------------  ----------  --------------  ------------------  -------------------\n",
      "6977d1df  mitre_attack_search           2           1.000               1.000                0.625\n"
     ]
    }
   ],
   "source": [
    "!python llm_as_a_judge_evaluator_agent.py ../Data-Agent-Rag/otel_traces_1.json rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOOL_USE_AVAILABLE_TOOLS=\"mitre_attack_search,virustotal_lookup,nvd_vulnerability_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace       tool_count  tools                Tool Use\n",
      "--------  ------------  -------------------  ----------\n",
      "6977d1df             1  mitre_attack_search\n",
      "\n",
      "Aggregated tool usage:\n",
      "- mitre_attack_search: 1 trace(s)\n",
      " You're running DeepEval's latest \u001b[35mTool Use Metric\u001b[0m! \u001b[1;90m(\u001b[0m\u001b[90musing gpt-\u001b[0m\u001b[1;90m4.1\u001b[0m\u001b[90m, \u001b[0m\n",
      "\u001b[90mstrict\u001b[0m\u001b[90m=\u001b[0m\u001b[3;90mFalse\u001b[0m\u001b[90m, \u001b[0m\u001b[90masync_mode\u001b[0m\u001b[90m=\u001b[0m\u001b[3;90mTrue\u001b[0m\u001b[1;90m)\u001b[0m\u001b[90m...\u001b[0m\n",
      "\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:00\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:01\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:02\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:03\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:04\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:05\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KEvaluating 1 test case(s) in parallel \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[?25htest case #0        \u001b[90m\u001b[0m \u001b[96m  0%\u001b[0m \u001b[94m0:00:06\u001b[0m\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  -  Tool Use (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The agent failed because, despite the sub-score indicating perfect tool selection in one instance, the final aggregated score of 0.0 is below the threshold of 0.5, indicating that across all evaluations, the agent did not consistently select appropriate tools for its tasks.\n",
      "The agent failed because it selected the 'mitre_attack_search' tool without providing required arguments, resulting in an irrelevant and ineffective tool call. This pattern of misuse led to a score of 0.0, which is below the passing threshold of 0.5., error: None)\n",
      "\n",
      "For conversational test case:\n",
      "\n",
      "  Turns:\n",
      " 0. user      What is the main technique used for bruteforce attack?\n",
      "       ctx[0]: brute force attack technique\n",
      "       ctx[1]: 1. Technique: Unknown Technique\n",
      "   Cosine similarity: 0.5402\n",
      "   Insight: Domain: enterprise Adversaries may use brute...\n",
      " 1. assistant Based on the **MITRE ATT&CK framework**, the main technique used for brute force attacks is **T1110: Brute Force**.\n",
      "\n",
      "## Key Details:\n",
      "\n",
      "**Primary Technique:** **T1110 - Brute Force**\n",
      "\n",
      "**Definition:** Adversaries use brute force techniques ...  | tools: mitre_attack_search\n",
      "       ctx[0]: brute force attack technique\n",
      "       ctx[1]: 1. Technique: Unknown Technique\n",
      "   Cosine similarity: 0.5402\n",
      "   Insight: Domain: enterprise Adversaries may use brute...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Tool Use: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\u001b[1;33m WARNING:\u001b[0m No hyperparameters logged.\n",
      " \u001b]8;id=564646;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\u001b[92m\u001b[0m Evaluation completed ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m6.\u001b[0m54s | token cost: \u001b[1;36m0.00729\u001b[0m USD\u001b[1m)\u001b[0m\n",
      " Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
      "    Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
      "\n",
      " ===============================================================================\n",
      "= \n",
      "\n",
      " Want to share evals with your team, or a place for your test cases to live? \n",
      "\n",
      "   Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[35mConfident AI\u001b[0m.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python llm_as_a_judge_evaluator_agent.py ../Data-Agent-Rag/otel_traces_1.json tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion \n",
    "\n",
    "Congratulations you implemented and instrumented a Strands Agent SDK with Amazon Bedrock Model which has observability through Amazon CloudWatch.\n",
    "\n",
    "- Strands travel agent.\n",
    "- Full OpenTelemetry tracing\n",
    "- Traces for Amazon Bedrock calls, Strands operations, etc.\n",
    "- Service name: agentic-travel-agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "Now that you have CrewAI with OpenTelemetry set up, you can:\n",
    "\n",
    "1. **Add More Agents**: Create a multi-agent architectures with different patterns\n",
    "2. **Add Tools to your agent**: Integrate search tools, API tools, or custom tools\n",
    "3. **[Set Up Alarms](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html)**: Create alarms on the metrics that are important to your business like `latency`, `token input`, and `token output` etc..\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865b774f",
   "metadata": {},
   "source": [
    "<div class=\"title-slide\">\n",
    "  \n",
    "# Module 2.1 - Evaluation Frameworks and Tools   \n",
    "<span style=\"font-size:20px; line-height:2;\">\n",
    "Dr. Hari Manassery Koduvely <br> \n",
    "Principal Data Scientist  <br>  \n",
    "Cybersecurity Analytics <br>  \n",
    "Ottawa, Canada <br>  \n",
    "December 08, 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d4b646",
   "metadata": {},
   "source": [
    "## How to Clone this Respository on your Work Laptop   \n",
    "- <span style=\"font-size:18px;\">If your laptop do not have Git, install from https://github.com/git-guides/install-git</span>  \n",
    "- <span style=\"font-size:18px;\">If your laptop do not have an IDE to open Jupyter Notebook install Vistual Studio Code from here https://code.visualstudio.com/download</span>  \n",
    "- <span style=\"font-size:18px;\">To clone the repository:</span>  \n",
    "    - <span style=\"font-size:16px;\">git clone https://github.com/harik68/Course-Evaluation-of-GenAI-Applications.git</span>  \n",
    "    - <span style=\"font-size:16px;\">git clone https://github.com/harik68/Course-Evaluation-of-GenAI-Applications.git</span>  \n",
    "- <span style=\"font-size:18px;\">Change directory to Course-Evaluation-of-GenAI-Applications/Session-1-Evaluation-Principles-and-Methods</span>  \n",
    "- <span style=\"font-size:18px;\">Open the Jupyter Notebook Module1.1-Foundations-of-GenAI-Evaluation.ipynb using the IDE</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5801c93",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e42f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import textwrap\n",
    "import os \n",
    "import openai  \n",
    "from IPython.display import Image, display, HTML\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfc9d1",
   "metadata": {},
   "source": [
    "## Quick Recap of Session 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c1215",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">**GenAI Application** evaluation is a Holistic Process.</span>  \n",
    "- <span style=\"font-size:18px;\">**Reference-Based** and **Reference-Free** Evaluations.</span>    \n",
    "- <span style=\"font-size:18px;\">**Classical Metrics** for Reference-Based Evaluations for Text Generation use cases.</span>    \n",
    "    - <span style=\"font-size:16px;\">ROUGE</span>    \n",
    "    - <span style=\"font-size:16px;\">BLEU</span>  \n",
    "    - <span style=\"font-size:16px;\">METEOR</span>    \n",
    "    - <span style=\"font-size:16px;\">BERT Score</span>    \n",
    "- <span style=\"font-size:18px;\">**LLM-as-a-Judge** method</span>    \n",
    "    - <span style=\"font-size:16px;\">Single output scoring without a reference.</span>    \n",
    "    - <span style=\"font-size:16px;\">Single output scoring with a reference.</span>    \n",
    "    - <span style=\"font-size:16px;\">Pairwise comparison.</span>    \n",
    "- <span style=\"font-size:18px;\">LLM-as-a-Judge method **Prompt Guidelines**</span>  \n",
    "    - <span style=\"font-size:16px;\">Discrete scores</span>  \n",
    "    - <span style=\"font-size:16px;\">Rubrics</span> \n",
    "- <span style=\"font-size:18px;\">**Biases** in  LLM-as-a-Judge method and their mitigations.</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b20064",
   "metadata": {},
   "source": [
    "[**Reference to Session 1 Jupyter Notebook**](./Module2.1-Evaluation-Frameworks-and-Tools.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa94683b",
   "metadata": {},
   "source": [
    "## Sesssion 2 Learning Objectives \n",
    "\n",
    "- <span style=\"font-size:18px;\"> What is **Observability** ?</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> How to instrument Observability using **Open Telemetry**</span> \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> **G-Eval** Framework </span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> **RAGAS** Framework </span>   \n",
    "\n",
    "- <span style=\"font-size:18px;\"> Open Source tool **DeepEval** </span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\"> **DAG Eval** Framework </span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313c02b",
   "metadata": {},
   "source": [
    "## Observability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9190bc",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">**External queries**: Ask about system behavior without needing internal knowledge.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Faster troubleshooting**: Diagnose and resolve novel problems quickly.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Behavior explanation**: Surface signals that reveal why something is happening.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c902dde9",
   "metadata": {},
   "source": [
    "## Telemetry "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8004c2d",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">Data emitted from a system and its behavior.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Data comes in the form of signals:  </span>\n",
    "    - <span style=\"font-size:16px;\">Spans  </span>\n",
    "    - <span style=\"font-size:16px;\">Traces  </span>\n",
    "    - <span style=\"font-size:16px;\">Metrics  </span>\n",
    "    - <span style=\"font-size:16px;\">Logs   </span>   \n",
    "- <span style=\"font-size:18px;\">**Open Telemetry** - an open source **industry standard** for instrumenting observability. </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3346c",
   "metadata": {},
   "source": [
    "## Different Instrumentation Methodologies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90684e",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">**1.SDK-based (Decorators/Wrappers)**:</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Mechanism: Developers manually wrap functions or use a vendor-specific SDK client.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Pros:</span>   \n",
    "    - <span style=\"font-size:16px;\">Highest granularity.</span>  \n",
    "    - <span style=\"font-size:16px;\">Allows capturing custom metadata and intermediate reasoning steps easily.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Cons:</span>   \n",
    "    - <span style=\"font-size:16px;\">High code intrusion.</span>  \n",
    "    - <span style=\"font-size:16px;\">Creates vendor lock-in.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Supporting Frameworks: LangSmith, Langfuse, MLflow.</span>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f029c",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">**2.Auto-Instrumentation using OpenTelemetry Standards (OTel)**:</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Mechanism: **Monkey-patch** (replace original function with a wrapped function) a standard library (e.g ChatCompletion.create from OpenAI) at run time to:</span>  \n",
    "\n",
    "    - <span style=\"font-size:16px;\">Emit traces.</span>  \n",
    "      \n",
    "    - <span style=\"font-size:16px;\">Calls the original API.</span>  \n",
    "      \n",
    "- <span style=\"font-size:16px;\">Pros:</span>  \n",
    "    - <span style=\"font-size:16px;\">Minimal code changes (often just an initialization line @autotrace)</span>  \n",
    "    - <span style=\"font-size:16px;\">Vendor-neutral (can switch backends easily)</span>  \n",
    "    - <span style=\"font-size:16px;\">Compliant with industry standards.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Cons:  \n",
    "    - <span style=\"font-size:16px;\">Could create conflict with other libraries.</span>  \n",
    "    - <span style=\"font-size:16px;\">Less control over exactly what is logged compared to manual decorators.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Supporting Frameworks: OpenLLMetry, OpenLIT, Arize Phoenix.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ccc53",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"font-size:18px;\">**3.Proxy-based**:</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Mechanism: The application routes LLM requests through a middleware proxy server.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Pros:</span>  \n",
    "    - <span style=\"font-size:16px;\">Zero overhead on the application.</span>  \n",
    "    - <span style=\"font-size:16px;\">Language agnostic.</span>  \n",
    "    - <span style=\"font-size:16px;\">Easiest to set up.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Cons:</span>   \n",
    "    - <span style=\"font-size:16px;\"> \"Black box\" visibility (sees inputs/outputs but not internal app logic/retrieval steps)</span>  \n",
    "    - <span style=\"font-size:16px;\"> Adds a network hop.</span>  \n",
    "\n",
    "- <span style=\"font-size:16px;\">Supporting Frameworks: Helicone, MLflow AI Gateway.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690479c0",
   "metadata": {},
   "source": [
    "## What Does Observability Data Contains?  \n",
    "- <span style=\"font-size:20px;\">Traces, which record the complete end-to-end journey of a request through the application.</span>  \n",
    " \n",
    "- <span style=\"font-size:20px;\">Spans, each of which represent a single timed unit of work within a trace.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71072ce",
   "metadata": {},
   "source": [
    "### Spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559cb38",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">**Unit of work**: represents a single request. </span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Tracks** operations within a request.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Reveals** what happened during execution.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Open Telemetry Span Contains**:</span>  \n",
    "    - <span style=\"font-size:16px;\">Name</span>    \n",
    "    - <span style=\"font-size:16px;\">Parent Span ID</span>  \n",
    "    - <span style=\"font-size:16px;\">Start and End Timestamps</span>    \n",
    "    - <span style=\"font-size:16px;\">Span Context</span>     \n",
    "    - <span style=\"font-size:16px;\">Attributes</span>  \n",
    "    - <span style=\"font-size:16px;\">Span Events</span>  \n",
    "    - <span style=\"font-size:16px;\">Span Links</span>  \n",
    "    - <span style=\"font-size:16px;\">Span Status</span>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e609f",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Span-Trace-Example.png' height='800'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 1 A: An Example for a Span in Telemetry Data.<br>\n",
    "        Reference: Open Telemetry Documentation.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d71a9c",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Span-Semantic-Conventions.png' height='500'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 1 B: Span Semantic Conventions.<br>\n",
    "        Reference: Open Telemetry Documentation.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba67c42",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Span-Types.png' height='400'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 1 C: Span Types.<br>\n",
    "        Reference: Open Telemetry Documentation.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3216ed6",
   "metadata": {},
   "source": [
    "### Traces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8192289",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">The path of a request through the application. </span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Consists of multiple Spans.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Gives the full picture of end-to-end operations during a request.</span> \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b1c0b",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Trace-Fibonacci-Agent.png' height='800'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 2: An Example for a Trace.<br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc444e1c",
   "metadata": {},
   "source": [
    "## Exercise 1: Hellow World Example for Tracing with OpenTelemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opentracing\n",
    "%pip install opentelemetry-sdk  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0e167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a48a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = TracerProvider()\n",
    "console_exporter = ConsoleSpanExporter()\n",
    "provider.add_span_processor(SimpleSpanProcessor(console_exporter))\n",
    "trace.set_tracer_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f248758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = trace.get_tracer(\"hello-world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9969434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from tracing import init_tracer\n",
    "import opentracing\n",
    "tracer = opentracing.tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ceec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_hello(hello_to):\n",
    "    with tracer.start_as_current_span(\"say-hello\") as span:\n",
    "        span.set_attribute(\"hello-to\", hello_to)\n",
    "        hello_str = format_string(hello_to)\n",
    "        print_hello(hello_str)\n",
    "\n",
    "def format_string(hello_to):\n",
    "    with tracer.start_as_current_span(\"format\") as span:\n",
    "        hello_str = f\"Hello, {hello_to}!\"\n",
    "        span.add_event(\"string-format\", {\"value\": hello_str})\n",
    "        return hello_str\n",
    "\n",
    "def print_hello(hello_str):\n",
    "    with tracer.start_as_current_span(\"println\") as span:\n",
    "        print(hello_str)\n",
    "        span.add_event(\"println\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8c076cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"format\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x2a460edf3cce036d459b988721750d0a\",\n",
      "        \"span_id\": \"0xa953b1f6de2653f6\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x54afe178c32c995e\",\n",
      "    \"start_time\": \"2025-12-03T21:45:15.823589Z\",\n",
      "    \"end_time\": \"2025-12-03T21:45:15.823612Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {},\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"string-format\",\n",
      "            \"timestamp\": \"2025-12-03T21:45:15.823605Z\",\n",
      "            \"attributes\": {\n",
      "                \"value\": \"Hello, World!\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.39.0\",\n",
      "            \"service.name\": \"unknown_service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "Hello, World!\n",
      "{\n",
      "    \"name\": \"println\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x2a460edf3cce036d459b988721750d0a\",\n",
      "        \"span_id\": \"0xf49b33961ee374ea\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x54afe178c32c995e\",\n",
      "    \"start_time\": \"2025-12-03T21:45:15.824694Z\",\n",
      "    \"end_time\": \"2025-12-03T21:45:15.824737Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {},\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"println\",\n",
      "            \"timestamp\": \"2025-12-03T21:45:15.824730Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.39.0\",\n",
      "            \"service.name\": \"unknown_service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"say-hello\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x2a460edf3cce036d459b988721750d0a\",\n",
      "        \"span_id\": \"0x54afe178c32c995e\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-12-03T21:45:15.823539Z\",\n",
      "    \"end_time\": \"2025-12-03T21:45:15.825537Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"hello-to\": \"World\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.39.0\",\n",
      "            \"service.name\": \"unknown_service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(say_hello(\"World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed140f",
   "metadata": {},
   "source": [
    "## Top Observability Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cf284",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Top-Observability-Frameworks.png' height='500'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 3: Comparison between Top Observability Frameworks.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f071fc",
   "metadata": {},
   "source": [
    "## Observability Frameworks in AWS Azure and GCP AI Studios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f65ad",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/Observability-Comparison-AWS-GCP-Azure.png' height='550'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 4: Comparison between Observability Frameworks in AWS AZure and GCP AI Studios.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678add6a",
   "metadata": {},
   "source": [
    "================================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dc8c2",
   "metadata": {},
   "source": [
    "## G-Eval Framework  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b18167",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/G-Eval-Framework.png' height='500'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 5: G-Eval Publication.<br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f4e96",
   "metadata": {},
   "source": [
    "-<span style=\"font-size:20px;\">A structured approach to evaluate GenAI outputs on a Reference-free basis.</span>     \n",
    "  \n",
    "-<span style=\"font-size:20px;\">Combibes *Automatic Chain-of-Thought Reasoning* and *Probability-Weighted Scoring*.</span>    \n",
    "    \n",
    "-<span style=\"font-size:20px;\">Achives better alignment with human judgements.</span>      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b2198",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/High-Level-G-Eval-Framework.png' height='600'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 5: G-Eval Overview.<br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278a66a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">**Step1**: Design a detailed natural languge prompt that explicitly define the evaluation task and criteria.</span>  \n",
    "  \n",
    "<span style=\"font-size:18px;\">**Step2**: Automatic Chain-of-Thought Generation.</span>  \n",
    "     \n",
    "<span style=\"font-size:16px;\">LLM generates it own detailed evaluation stepss based on the task and criteria.</span>    \n",
    "  \n",
    "<span style=\"font-size:18px;\">**Step3**: Calculation of Probability-weighted score.</span>  \n",
    "<span style=\"font-size:20px;\">\n",
    "$$\n",
    "score = \\sum_{i=1}^{n} p(s_i)\\space s_i \n",
    "$$\n",
    "</span>\n",
    "<span style=\"font-size:16px;\">Where $\\{s_1, s_2, ..., s_n\\}$ represents set of possible integer scores defined in the criteria.</span>   \n",
    "  \n",
    "<span style=\"font-size:16px;\">And $p(s_i)$ is the probability of generating token $s_i$ by LLM.</span>  \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5512e24",
   "metadata": {},
   "source": [
    "## RAGAS (Retrieval Augmented Generation Assessment) Framework \n",
    "<span style=\"font-size:20px;\">Retrieval Augmented Generation (RAG) is an efficient and cost-effective way to solve 3 main drawbacks of LLMs:</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Lack of internal knowledge about events past their training cut-off date.</span>      \n",
    "      \n",
    "- <span style=\"font-size:18px;\">Lack of sufficient knowledge about highly specialized domains or company internal documents.</span>      \n",
    "      \n",
    "- <span style=\"font-size:18px;\">Prone to generating factually incorrect information.</span>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102bacbe",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/RAG-High-Level-Architecture.png' height='600'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 6: RAG High-Level Architecture.<br>\n",
    "        Reference: AWS RAG Documentation.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3c09d",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px;\">Challenges in evaluation of RAG systems:</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Interplay of Components**: Quality of final answer depends on both the retriever and the generator.</span>  \n",
    "    \n",
    "- <span style=\"font-size:18px;\">**Lack of Universal Benchmarks**: No single benchmark dataset that applies to every RAG system.</span>   \n",
    "\n",
    "- <span style=\"font-size:18px;\">**Dynamic Data and Drift**: Evaluation results can be outdated quickly when knowledge base get udated.</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">**Cost of Human Evaluation**: Frequent Human evaluation is time consuming and costly.</span>  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35461ba1",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/RAGaS-Framework-Paper.png' height='600'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 7: RAGAS Framework Paper.<br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c5bff",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px;\">RAGAS Introduced 3 core Metrics.</span>   \n",
    "    \n",
    "<span style=\"font-size:20px;\">1. **Faithfulness**: Measures whether claims in the generated answer can be supported by the retrieved context.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Direct measure of the degree of hallucination.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Judge-LLM extracts individual statements from the geneerated answer.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Verifies each statement against the context.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Faithfulness Score F is calculated as:</span>  \n",
    "<span style=\"font-size:18px;\">\n",
    "$$\n",
    "F = \\frac{V}{S}\n",
    "$$\n",
    "<span style=\"font-size:18px;\"></span>  \n",
    "- <span style=\"font-size:18px;\"> V - Number of verified statements.</span>      \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> S - Number of total statements.</span>     \n",
    "\n",
    "<span style=\"font-size:20px;\">2. **Answer Relevance**: Measures whether the generated response directly address the original question.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Judge-LLM first generate the potential questions the given answer could respond to.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Theen compute the average cosine similarity between generated questions and the original query</span>  \n",
    "- <span style=\"font-size:18px;\">Answer Relevance Score AR is calculated as:</span>  \n",
    "<span style=\"font-size:18px;\">\n",
    "$$\n",
    "AR = \\frac{1}{n}\\space \\sum_{i=1}^{n}sim(q,q_i)\n",
    "$$\n",
    "<span style=\"font-size:18px;\"></span>  \n",
    "<span style=\"font-size:20px;\">2. **Context Relevance**: Measures how relevant the context is for answering the original question.</span> \n",
    "\n",
    "- <span style=\"font-size:18px;\">Judge-LLM extracts sentences from the context that are essential for answering the question.</span>    \n",
    "- <span style=\"font-size:18px;\">Context Relevance Score CR is calculated as:</span>  \n",
    "<span style=\"font-size:18px;\">\n",
    "$$\n",
    "CR = \\frac{E}{S}\n",
    "$$\n",
    "<span style=\"font-size:18px;\"></span>  \n",
    "- <span style=\"font-size:18px;\"> E - Number of extracted sentences from context.</span>      \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> S - Number of total sentences in context.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83c553",
   "metadata": {},
   "source": [
    "## DeepEval Open-Source Evaluation Framework  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d110647",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\"> Built on top of G-Eval framework.</span>     \n",
    "    \n",
    "- <span style=\"font-size:18px;\"> Plug-and-Use 30+ LLM-evaluated metrics.</span>      \n",
    "   \n",
    "- <span style=\"font-size:18px;\"> Supports both end-to-end and component level evaluation.</span>   \n",
    "   \n",
    "- <span style=\"font-size:18px;\"> Evaluation for RAG, Agents, Chatbots etc.</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> Synthetic dataset generation capability.</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> Customizable metrics.</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\"> SecOps support for red teaming and safety scan for vulnerabilitites.</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27863d3d",
   "metadata": {},
   "source": [
    "### Plug-and-Use Metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae28f27",
   "metadata": {},
   "source": [
    " <span style=\"font-size:22px;\">1. Custom Metrics</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946ffb0",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">G-Eval</span>   \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Deep Acyclic Graph (DAG) Eval</span>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5897deb",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px;\">Example: Summarizaing Meeting Notes</span>  \n",
    "\n",
    "<span style=\"font-size:18px;\">G-Eval:</span>  \n",
    "  \n",
    "<span style=\"font-size:18px:\"> A single prompt: <br>\"Score is 0 if the summmary misses any of the headings: \"intro\", \"body\", \"conclusion\". <br> Score is 2 if the summary has all the 3 sections but are in the wrong order. <br>Score is 10 if the summary hasa all the 3 sections and they are in the correct order.\"</span>  \n",
    "  \n",
    "<span style=\"font-size:18px;\">DAG Eval:</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a398f5",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <img src='../Images/DeepEval-DAGEval.png' height='600'>\n",
    "    <div style='font-size:16px; color:gray; margin-top:8px;'>\n",
    "        Figure 8: DAG Eval Metric in DeepEval.<br>\n",
    "        Reference: Deep Eval Documentation\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f28a46",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px;\">Advantages of DAG Eval over G-Eval</span>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efb7e6",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">**Determinism**: Structured decision-tree approach ensures more consistent and reproducible results.</span> \n",
    "    \n",
    "- <span style=\"font-size:18px;\">**Granular Control and Transparency**: Developers can define explicit sequence of checks to create a more auditable trail.</span>   \n",
    "   \n",
    "- <span style=\"font-size:18px;\">**Syntax and Structural Evaluations**: G-Eval struggles with strict structural checks such as \"must have this JSON schema\".</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\">**Modular Design**: One can use G-Eval as a node within a DAG to leverage</span>  \n",
    "    - <span style=\"font-size:18px;\">G-Eval's subjective strength.</span>  \n",
    "      \n",
    "    - <span style=\"font-size:18px;\">Deterministic conditions for structure and syntax.</span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654d774",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;\"> 2. RAG Metrics</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420fd59b",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px;\">Retriever Metrics:</span>  \n",
    "- <span style=\"font-size:18px;\">Contextual Relevancy</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Contextual Precision</span>    \n",
    "\n",
    "- <span style=\"font-size:18px;\">Contextual Recall</span>    \n",
    "\n",
    "<span style=\"font-size:20px;\">Generator Metrics:</span>  \n",
    "- <span style=\"font-size:18px;\">Answer Relevancy</span>    \n",
    "\n",
    "- <span style=\"font-size:18px;\">Faithfulness</span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6196a9",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;\"> 3. Agent Metrics</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c86fa0",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">Task Completion</span>    \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Tool Correctness</span>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589386a7",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;\">4. Multi-Turn Chat Metrics</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e49521",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">Knowledge Retention</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Role Adherence</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Conversation Completeness</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Conversation Relevancy</span>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649c65a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;\">5. Multi-Modal Metrics</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd5502",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">Image Coherence / Helpfulness / Reference</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Text-to-Image</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Multimodal Contextual Relevancy / Recall / Precision</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Multimodal Answer Relevancy / Faithfulness</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6cea1",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;\">6. Safety Metrics</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a1db3",
   "metadata": {},
   "source": [
    "- <span style=\"font-size:18px;\">Bias</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Toxicity</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Misuse</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">PII Leakage</span>  \n",
    "\n",
    "- <span style=\"font-size:18px;\">Role Violation</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce007a64",
   "metadata": {},
   "source": [
    "## Exercise 1  \n",
    "<span style=\"font-size:20px;\">Perform evaluation of text summarization using G-Eval and DAG Eval.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685c029",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Installing DeepEval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (24.0)\n",
      "Collecting pip\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.3\n",
      "Successfully installed pip-25.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install --upgrade setuptools\n",
    "!pip3 install --no-cache-dir grpcio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f674b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepeval==3.7.3\n",
      "  Downloading deepeval-3.7.3-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading deepeval-3.7.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.9.5)\n",
      "Requirement already satisfied: anthropic in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.75.0)\n",
      "Requirement already satisfied: click<8.3.0,>=8.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (8.1.7)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.76.0)\n",
      "Requirement already satisfied: jinja2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.1.4)\n",
      "Requirement already satisfied: nest_asyncio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.6.0)\n",
      "Requirement already satisfied: ollama in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.6.1)\n",
      "Requirement already satisfied: openai in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.8.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: portalocker in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.9.5)\n",
      "Requirement already satisfied: anthropic in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.75.0)\n",
      "Requirement already satisfied: click<8.3.0,>=8.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (8.1.7)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.76.0)\n",
      "Requirement already satisfied: jinja2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.1.4)\n",
      "Requirement already satisfied: nest_asyncio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.6.0)\n",
      "Requirement already satisfied: ollama in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.6.1)\n",
      "Requirement already satisfied: openai in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.8.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: portalocker in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.2.0)\n",
      "Collecting posthog<6.0.0,>=5.4.0 (from deepeval==3.7.3)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting posthog<6.0.0,>=5.4.0 (from deepeval==3.7.3)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.12.5)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.12.0)\n",
      "Requirement already satisfied: pyfiglet in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.0.4)\n",
      "Requirement already satisfied: pytest in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (9.0.2)\n",
      "Requirement already satisfied: pytest-asyncio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: pytest-repeat in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: pytest-rerunfailures in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (12.0)\n",
      "Requirement already satisfied: pytest-xdist in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.8.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.32.2)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (13.7.1)\n",
      "Requirement already satisfied: sentry-sdk in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.47.0)\n",
      "Requirement already satisfied: setuptools in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (80.9.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.9.0)\n",
      "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (8.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (4.66.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.12.3)\n",
      "Requirement already satisfied: wheel in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.43.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.12.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (2.43.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.28.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (3.7)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.9.1)\n",
      "Requirement already satisfied: certifi in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.7.3) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.7.3) (3.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.12.5)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.12.0)\n",
      "Requirement already satisfied: pyfiglet in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.0.4)\n",
      "Requirement already satisfied: pytest in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (9.0.2)\n",
      "Requirement already satisfied: pytest-asyncio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: pytest-repeat in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: pytest-rerunfailures in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (12.0)\n",
      "Requirement already satisfied: pytest-xdist in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (3.8.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (1.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.32.2)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (13.7.1)\n",
      "Requirement already satisfied: sentry-sdk in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (2.47.0)\n",
      "Requirement already satisfied: setuptools in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (80.9.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.9.0)\n",
      "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (8.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (4.66.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.12.3)\n",
      "Requirement already satisfied: wheel in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from deepeval==3.7.3) (0.43.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.12.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (2.43.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.28.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (3.7)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (4.9.1)\n",
      "Requirement already satisfied: certifi in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.7.3) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.7.3) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-proto==1.39.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (6.33.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval==3.7.3) (0.60b0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (2.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.7.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.7.3) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval==3.7.3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval==3.7.3) (2.18.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (1.39.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-proto==1.39.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.3) (6.33.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval==3.7.3) (0.60b0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (2.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.11.7->deepeval==3.7.3) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.7.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.7.3) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval==3.7.3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rich<15.0.0,>=13.6.0->deepeval==3.7.3) (2.18.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.6.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from typer<1.0.0,>=0.9->deepeval==3.7.3) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval==3.7.3) (0.1.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.3) (0.6.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from typer<1.0.0,>=0.9->deepeval==3.7.3) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval==3.7.3) (0.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.9.4)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from jinja2->deepeval==3.7.3) (2.1.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from aiohttp->deepeval==3.7.3) (1.9.4)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from anthropic->deepeval==3.7.3) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from jinja2->deepeval==3.7.3) (2.1.5)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (2.3.0)\n",
      "Requirement already satisfied: packaging>=22 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (24.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (1.6.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest-xdist->deepeval==3.7.3) (2.1.2)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (2.3.0)\n",
      "Requirement already satisfied: packaging>=22 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (24.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest->deepeval==3.7.3) (1.6.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /Users/harikoduvely/miniconda3/envs/llm_env/lib/python3.11/site-packages (from pytest-xdist->deepeval==3.7.3) (2.1.2)\n",
      "Downloading deepeval-3.7.3-py3-none-any.whl (727 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/727.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading deepeval-3.7.3-py3-none-any.whl (727 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.3/727.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.3/727.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Installing collected packages: posthog, deepeval\n",
      "\u001b[2K  Attempting uninstall: posthog\n",
      "\u001b[2K    Found existing installation: posthog 6.9.3\n",
      "\u001b[2K    Uninstalling posthog-6.9.3:\n",
      "\u001b[2K      Successfully uninstalled posthog-6.9.3\n",
      "Installing collected packages: posthog, deepeval\n",
      "\u001b[2K  Attempting uninstall: posthog\n",
      "\u001b[2K    Found existing installation: posthog 6.9.3\n",
      "\u001b[2K    Uninstalling posthog-6.9.3:\n",
      "\u001b[2K      Successfully uninstalled posthog-6.9.3\n",
      "\u001b[2K  Attempting uninstall: deepeval━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [posthog]\n",
      "\u001b[2K    Found existing installation: deepeval 3.6.9m \u001b[32m0/2\u001b[0m [posthog]\n",
      "\u001b[2K  Attempting uninstall: deepeval━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [posthog]\n",
      "\u001b[2K    Found existing installation: deepeval 3.6.9m \u001b[32m0/2\u001b[0m [posthog]\n",
      "\u001b[2K    Uninstalling deepeval-3.6.9:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [deepeval]\n",
      "\u001b[2K    Uninstalling deepeval-3.6.9:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [deepeval]\n",
      "\u001b[2K      Successfully uninstalled deepeval-3.6.9━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [deepeval]\n",
      "\u001b[2K      Successfully uninstalled deepeval-3.6.9━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [deepeval]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [deepeval]1/2\u001b[0m [deepeval]\n",
      "\u001b[1A\u001b[2KSuccessfully installed deepeval-3.7.3 posthog-5.4.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [deepeval]\n",
      "\u001b[1A\u001b[2KSuccessfully installed deepeval-3.7.3 posthog-5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deepeval==3.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58345ada",
   "metadata": {},
   "source": [
    "**IMPORTANT: Restart the Kernel after installing deepeval before proceeding further**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec403fe",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Import Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccfa38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase,LLMTestCaseParams\n",
    "from deepeval import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f7afc",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Setting up Open AI API for LLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"  # Replace with your actual API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8665e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3681f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train data\n",
    "df_train = pd.read_csv('../Data-Summarization/train_sample.csv')\n",
    "article_text = df_train.loc[0, 'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da32974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summarization_prompt(article_text: str, summary_length: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Generates a prompt for text summarization to send to the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        article_text (str): The input article or document to summarize.\n",
    "        summary_length (int): Desired length of the summary in words (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted prompt for the OpenAI API.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Summarize the following article in about {summary_length} words:\\n\\n\"\n",
    "        f\"Article:\\n{article_text}\\n\\n\"\n",
    "        \"Summary:\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8026f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatgpt_response(prompt, model=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    Sends a query to ChatGPT API and returns the model's response text.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The question or instruction for the model.\n",
    "        model (str): Model name to use (default: \"gpt-4.1-mini\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The text output from ChatGPT.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the message text\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44ef13",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Generate Prompt for Summarization</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1c53f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following article in about 200 words:  Article: A woman in the Northwest Highlands of\n",
      "Scotland who'd fallen ill tested negative for Ebola, the Scottish government said Tuesday. A\n",
      "spokesman for the government said the woman had been in West Africa recently, though she had no\n",
      "direct contact with anyone with Ebola. \"A patient at Aberdeen Royal Infirmary has tested negative\n",
      "for Ebola,\" the press release said. \"The individual was transferred to the hospital by the Scottish\n",
      "Ambulance Service yesterday after falling ill while visiting Torridon in the Scottish Highlands.\"\n",
      "Meanwhile, a health care worker who was diagnosed with the Ebola virus after returning to Scotland\n",
      "from Sierra Leone was transferred to the Royal Free Hospital in London. The patient is Pauline\n",
      "Cafferkey, 39, of Glasgow, Scotland, the hospital said. She was working with Save the Children at an\n",
      "Ebola treatment center, said Michael von Bertele, humanitarian director at that organization. She\n",
      "traveled via Casablanca, Morocco, and London Heathrow Airport before arriving at Glasgow Airport on\n",
      "a British Airways flight late Sunday, the health agency NHS Scotland said. After feeling unwell, she\n",
      "sought medical attention and became the first person to be diagnosed with Ebola within the United\n",
      "Kingdom. British media outlets said Cafferkey is a public health nurse in Scotland's South\n",
      "Lanarkshire area who was part of a 30-strong team of medical volunteers deployed to West Africa by\n",
      "the UK government last month in a joint endeavor with Save the Children. She was reportedly\n",
      "transferred to London in a military aircraft fitted with an isolation pod. The Royal Free Hospital\n",
      "is equipped with a high-level isolation unit, with access restricted to specially trained medical\n",
      "staff. A specially designed tent, with controlled ventilation, is set up over the patient's bed. A\n",
      "British volunteer nurse, William Pooley, was successfully treated in the unit after he was brought\n",
      "home from Sierra Leone in August, having been diagnosed with Ebola there. 'Extremely low' risk . UK\n",
      "authorities are working to trace those who have come into contact with Cafferkey. The Scottish\n",
      "government has set up a special number for people to call if they traveled on the same London\n",
      "Heathrow-to-Glasgow flight as Cafferkey. British Airways said it was working closely with health\n",
      "authorities in England and Scotland and would help with any information needed. \"The safety and\n",
      "security of our customers and crew is always our top priority and the risk to people on board that\n",
      "individual flight is extremely low,\" the airline said. Ebola patients become infectious only after\n",
      "they display symptoms, such as fever and vomiting. The deadly virus is spread through contact with\n",
      "bodily fluids. A Downing Street spokesman told CNN that British Prime Minister David Cameron and\n",
      "Scottish First Minister Nicola Sturgeon had discussed the procedures in place to handle such a case.\n",
      "\"They agreed that both governments would remain in close touch and ensure everything possible was\n",
      "done to support the patient and, although the risk to the general population remained low, all\n",
      "measures would be taken to protect public health.\" Possible case . Another suspected Ebola case is\n",
      "being tested in southwest England at the Royal Cornwall Hospital, health officials said. \"We do not\n",
      "expect the results to be known for at least 24 hours and in the meantime the patient is being looked\n",
      "after in isolation, following nationally agreed guidelines and protocols to protect the health of\n",
      "our staff and other patients,\" said a joint statement from the hospital and Public Health England, a\n",
      "government agency. According to UK government guidelines, humanitarian workers returning from Ebola-\n",
      "affected countries in West Africa who've been at high risk of exposure are expected to monitor their\n",
      "own health for 21 days after they get home. As of December 24, at least 7,693 people had died in the\n",
      "current Ebola outbreak, centered in Liberia, Sierra Leone and Guinea, the World Health Organization\n",
      "said. There have been at least 19,695 cases.  Summary:\n"
     ]
    }
   ],
   "source": [
    "summary_length = 200\n",
    "prompt = generate_summarization_prompt(article_text, summary_length)\n",
    "print(textwrap.fill(prompt, width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b6279",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Generate Summary Using OpenAI API</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e35ecb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "generated_summary = get_chatgpt_response(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a569b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman in the Northwest Highlands of Scotland tested negative for Ebola after falling ill, despite\n",
      "recently visiting West Africa. However, a health care worker named Pauline Cafferkey was diagnosed\n",
      "with Ebola after returning from Sierra Leone and was transferred to a hospital in London. Cafferkey\n",
      "had traveled via Casablanca and London before arriving in Scotland, where she sought medical\n",
      "attention. The Royal Free Hospital in London has a high-level isolation unit where Cafferkey was\n",
      "treated. UK authorities are working to trace those who came into contact with her, and another\n",
      "suspected Ebola case is being tested at a hospital in southwest England. As of December 24, there\n",
      "have been at least 7,693 deaths in the current Ebola outbreak in Liberia, Sierra Leone, and Guinea.\n",
      "The UK government guidelines require humanitarian workers returning from Ebola-affected countries to\n",
      "monitor their health for 21 days. Prime Minister David Cameron and First Minister Nicola Sturgeon\n",
      "have discussed measures to handle the cases and protect public health.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(generated_summary, width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1baae7",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Run G-Eval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b06aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running G-Eval ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcb884597f745649dbe9e2732a8a41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Coherence [GEval] (score: 0.8182425532696179, threshold: 0.7, strict: False, evaluation model: gpt-4.1-mini, reason: The summary maintains a clear and logical flow, progressing from the negative test of the woman in Scotland to the confirmed Ebola case of Pauline Cafferkey, then to the hospital treatment and public health responses. It captures key points such as Cafferkey's travel, treatment, contact tracing, and government actions in a well-organized manner without abrupt jumps. The summary avoids redundancy and irrelevant details, though it omits some specifics like the involvement of Save the Children and the detailed description of the isolation unit, which slightly reduces completeness but does not harm coherence., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: A woman in the Northwest Highlands of Scotland who'd fallen ill tested negative for Ebola, the Scottish government said Tuesday. A spokesman for the government said the woman had been in West Africa recently, though she had no direct contact with anyone with Ebola. \"A patient at Aberdeen Royal Infirmary has tested negative for Ebola,\" the press release said. \"The individual was transferred to the hospital by the Scottish Ambulance Service yesterday after falling ill while visiting Torridon in the Scottish Highlands.\" Meanwhile, a health care worker who was diagnosed with the Ebola virus after returning to Scotland from Sierra Leone was transferred to the Royal Free Hospital in London. The patient is Pauline Cafferkey, 39, of Glasgow, Scotland, the hospital said. She was working with Save the Children at an Ebola treatment center, said Michael von Bertele, humanitarian director at that organization. She traveled via Casablanca, Morocco, and London Heathrow Airport before arriving at Glasgow Airport on a British Airways flight late Sunday, the health agency NHS Scotland said. After feeling unwell, she sought medical attention and became the first person to be diagnosed with Ebola within the United Kingdom. British media outlets said Cafferkey is a public health nurse in Scotland's South Lanarkshire area who was part of a 30-strong team of medical volunteers deployed to West Africa by the UK government last month in a joint endeavor with Save the Children. She was reportedly transferred to London in a military aircraft fitted with an isolation pod. The Royal Free Hospital is equipped with a high-level isolation unit, with access restricted to specially trained medical staff. A specially designed tent, with controlled ventilation, is set up over the patient's bed. A British volunteer nurse, William Pooley, was successfully treated in the unit after he was brought home from Sierra Leone in August, having been diagnosed with Ebola there. 'Extremely low' risk . UK authorities are working to trace those who have come into contact with Cafferkey. The Scottish government has set up a special number for people to call if they traveled on the same London Heathrow-to-Glasgow flight as Cafferkey. British Airways said it was working closely with health authorities in England and Scotland and would help with any information needed. \"The safety and security of our customers and crew is always our top priority and the risk to people on board that individual flight is extremely low,\" the airline said. Ebola patients become infectious only after they display symptoms, such as fever and vomiting. The deadly virus is spread through contact with bodily fluids. A Downing Street spokesman told CNN that British Prime Minister David Cameron and Scottish First Minister Nicola Sturgeon had discussed the procedures in place to handle such a case. \"They agreed that both governments would remain in close touch and ensure everything possible was done to support the patient and, although the risk to the general population remained low, all measures would be taken to protect public health.\" Possible case . Another suspected Ebola case is being tested in southwest England at the Royal Cornwall Hospital, health officials said. \"We do not expect the results to be known for at least 24 hours and in the meantime the patient is being looked after in isolation, following nationally agreed guidelines and protocols to protect the health of our staff and other patients,\" said a joint statement from the hospital and Public Health England, a government agency. According to UK government guidelines, humanitarian workers returning from Ebola-affected countries in West Africa who've been at high risk of exposure are expected to monitor their own health for 21 days after they get home. As of December 24, at least 7,693 people had died in the current Ebola outbreak, centered in Liberia, Sierra Leone and Guinea, the World Health Organization said. There have been at least 19,695 cases.\n",
      "  - actual output: A woman in the Northwest Highlands of Scotland tested negative for Ebola after falling ill, despite recently visiting West Africa. However, a health care worker named Pauline Cafferkey was diagnosed with Ebola after returning from Sierra Leone and was transferred to a hospital in London. Cafferkey had traveled via Casablanca and London before arriving in Scotland, where she sought medical attention. The Royal Free Hospital in London has a high-level isolation unit where Cafferkey was treated. UK authorities are working to trace those who came into contact with her, and another suspected Ebola case is being tested at a hospital in southwest England. As of December 24, there have been at least 7,693 deaths in the current Ebola outbreak in Liberia, Sierra Leone, and Guinea. The UK government guidelines require humanitarian workers returning from Ebola-affected countries to monitor their health for 21 days. Prime Minister David Cameron and First Minister Nicola Sturgeon have discussed measures to handle the cases and protect public health.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Coherence [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">⚠ WARNING:</span> No hyperparameters logged.\n",
       "» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m⚠ WARNING:\u001b[0m No hyperparameters logged.\n",
       "» \u001b]8;id=298682;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Evaluation completed 🎉! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.</span>67s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0009520000000000002</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   » Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» Want to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Evaluation completed 🎉! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m7.\u001b[0m67s | token cost: \u001b[1;36m0.0009520000000000002\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   » Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» Want to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the G-Eval metric for coherence, specifying the judge model\n",
    "# Note: \"gpt-4.1-mini\" is a placeholder name used in documentation snippets; use \"gpt-4-turbo\" or the actual available model name.\n",
    "# If \"gpt-4.1-mini\" is unavailable, the code might require adjustment to a valid model name.\n",
    "coherence_metric_g_eval = GEval(\n",
    "    name=\"Coherence\",\n",
    "    criteria=\"The summary must be well-structured and well-organized, building from sentence to sentence to a coherent body of information.\",\n",
    "    model = \"gpt-4.1-mini\",  \n",
    "    threshold=0.7,\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    strict_mode=False\n",
    ")\n",
    "\n",
    "# Create a test case\n",
    "test_case_g_eval = LLMTestCase(\n",
    "    input=article_text,\n",
    "    actual_output=generated_summary\n",
    ")\n",
    "\n",
    "# Evaluate using G-Eval\n",
    "print(\"--- Running G-Eval ---\")\n",
    "g_eval_result = evaluate([test_case_g_eval], [coherence_metric_g_eval])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe1eb6",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Print G-Eval Results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Score: 0.8182425532696179\n",
      "Extracted Reason:\n",
      "The summary maintains a clear and logical flow, progressing from the negative test of the woman in\n",
      "Scotland to the confirmed Ebola case of Pauline Cafferkey, then to the hospital treatment and public\n",
      "health responses. It captures key points such as Cafferkey's travel, treatment, contact tracing, and\n",
      "government actions in a well-organized manner without abrupt jumps. The summary avoids redundancy\n",
      "and irrelevant details, though it omits some specifics like the involvement of Save the Children and\n",
      "the detailed description of the isolation unit, which slightly reduces completeness but does not\n",
      "harm coherence.\n"
     ]
    }
   ],
   "source": [
    "# Print the score and reason\n",
    "print(f\"Extracted Score: {g_eval_result.test_results[0].metrics_data[0].score}\")\n",
    "print(f\"Extracted Reason:\")\n",
    "print(textwrap.fill(g_eval_result.test_results[0].metrics_data[0].reason, width=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d9192",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Inspect the CoT Automatically Generated by G-Eval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad605663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extracted Chain of Thought (CoT) Logs ---\n",
      "Criteria:\n",
      "The summary must be well-structured and well-organized, building from sentence to sentence to a coherent body of information. \n",
      " \n",
      "Evaluation Steps:\n",
      "[\n",
      "    \"Compare the Input and Actual Output to ensure the summary logically progresses from one sentence to the next, maintaining a clear and coherent flow.\",\n",
      "    \"Check that the Actual Output captures the key points of the Input in a well-organized manner without abrupt jumps or disjointed information.\",\n",
      "    \"Verify that each sentence in the Actual Output builds upon the previous one, creating a structured and unified summary reflecting the Input content.\",\n",
      "    \"Assess whether the summary avoids redundancy and irrelevant details, focusing on a concise and coherent representation of the Input.\"\n",
      "] \n",
      " \n",
      "Rubric:\n",
      "None \n",
      " \n",
      "Score: 0.8182425532696179\n"
     ]
    }
   ],
   "source": [
    "# Access the verbose logs attribute\n",
    "cot_logs = g_eval_result.test_results[0].metrics_data[0].verbose_logs\n",
    "\n",
    "# Print the logs\n",
    "print(\"--- Extracted Chain of Thought (CoT) Logs ---\")\n",
    "print(cot_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82f8e8",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">Run DAG Eval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6406f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCaseParams, LLMTestCase\n",
    "from deepeval.metrics import GEval, DAGMetric\n",
    "#from deepeval.dag import DeepAcyclicGraph\n",
    "from deepeval.metrics.dag import DeepAcyclicGraph, BaseNode, VerdictNode\n",
    "from typing import Optional, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16376e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = LLMTestCase(\n",
    "    input=\"\"\"\n",
    "Alice: \"Today's agenda: product update, blockers, and marketing timeline. Bob, updates?\"\n",
    "Bob: \"Core features are done, but we're optimizing performance for large datasets. Fixes by Friday, testing next week.\"\n",
    "Alice: \"Charlie, does this timeline work for marketing?\"\n",
    "Charlie: \"We need finalized messaging by Monday.\"\n",
    "Alice: \"Bob, can we provide a stable version by then?\"\n",
    "Bob: \"Yes, we'll share an early build.\"\n",
    "Charlie: \"Great, we'll start preparing assets.\"\n",
    "Alice: \"Plan: fixes by Friday, marketing prep Monday, sync next Wednesday. Thanks, everyone!\"\n",
    "\"\"\",\n",
    "    actual_output=\"\"\"\n",
    "Intro:\n",
    "Alice outlined the agenda: product updates, blockers, and marketing alignment.\n",
    "\n",
    "Body:\n",
    "Bob reported performance issues being optimized, with fixes expected by Friday. Charlie requested finalized messaging by Monday for marketing preparation. Bob confirmed an early stable build would be ready.\n",
    "\n",
    "Conclusion:\n",
    "The team aligned on next steps: engineering finalizing fixes, marketing preparing content, and a follow-up sync scheduled for Wednesday.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a3efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepeval.metrics.dag import (\n",
    "    DeepAcyclicGraph,\n",
    "    TaskNode,\n",
    "    BinaryJudgementNode,\n",
    "    NonBinaryJudgementNode,\n",
    "    VerdictNode,\n",
    ")\n",
    "\n",
    "correct_order_node = NonBinaryJudgementNode(\n",
    "    criteria=\"Are the summary headings in the correct order: 'intro' => 'body' => 'conclusion'?\",\n",
    "    children=[\n",
    "        VerdictNode(verdict=\"Yes\", score=10),\n",
    "        VerdictNode(verdict=\"Two are out of order\", score=4),\n",
    "        VerdictNode(verdict=\"All out of order\", score=2),\n",
    "    ],\n",
    ")\n",
    "\n",
    "correct_headings_node = BinaryJudgementNode(\n",
    "    criteria=\"Does the summary headings contain all three: 'intro', 'body', and 'conclusion'?\",\n",
    "    children=[\n",
    "        VerdictNode(verdict=False, score=0),\n",
    "        VerdictNode(verdict=True, child=correct_order_node),\n",
    "    ],\n",
    ")\n",
    "\n",
    "extract_headings_node = TaskNode(\n",
    "    instructions=\"Extract all headings in `actual_output`\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    output_label=\"Summary headings\",\n",
    "    children=[correct_headings_node, correct_order_node],\n",
    ")\n",
    "\n",
    "# create the DAG\n",
    "dag = DeepAcyclicGraph(root_nodes=[extract_headings_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3363a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93018d67f6ca44ca8e1c4c0c4354b981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_correctness = DAGMetric(name=\"Format Correctness\", dag=dag)\n",
    "format_correctness.measure(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd4e0206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "The score for Format Correctness [DAG] is 1.0 because, according to the DAG traversal, all required\n",
      "summary headings ('Intro:', 'Body:', 'Conclusion:') were present (BinaryJudgementNode) and in the\n",
      "correct order (NonBinaryJudgementNode), leading to a final deterministic verdict of 'Yes' at the\n",
      "VerdictNode.\n"
     ]
    }
   ],
   "source": [
    "print(format_correctness.score)\n",
    "print(textwrap.fill(format_correctness.reason, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5222876",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_g_eval = GEval(\n",
    "    name=\"Format Correctness\",\n",
    "    evaluation_steps=[\n",
    "        \"The `actual_output` is completely wrong if it misses any of the headings: 'intro', 'body', 'conclusion'.\",\n",
    "        \"If the `actual_output` has all the complete headings but are in the wrong order, penalize it.\",\n",
    "        \"If the summary has all the correct headings and they are in the right order, give it a perfect score.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33499c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running G-Eval ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Format Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFormat Correctness \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d83d55745cf45f4a2e847505b24e806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Format Correctness [GEval] (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The actual output contains all required headings: 'intro', 'body', and 'conclusion', and they are presented in the correct order. Each section is clearly labeled and the content under each heading is relevant and complete, fully aligning with the evaluation steps., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: \n",
      "Alice: \"Today's agenda: product update, blockers, and marketing timeline. Bob, updates?\"\n",
      "Bob: \"Core features are done, but we're optimizing performance for large datasets. Fixes by Friday, testing next week.\"\n",
      "Alice: \"Charlie, does this timeline work for marketing?\"\n",
      "Charlie: \"We need finalized messaging by Monday.\"\n",
      "Alice: \"Bob, can we provide a stable version by then?\"\n",
      "Bob: \"Yes, we'll share an early build.\"\n",
      "Charlie: \"Great, we'll start preparing assets.\"\n",
      "Alice: \"Plan: fixes by Friday, marketing prep Monday, sync next Wednesday. Thanks, everyone!\"\n",
      "\n",
      "  - actual output: \n",
      "Intro:\n",
      "Alice outlined the agenda: product updates, blockers, and marketing alignment.\n",
      "\n",
      "Body:\n",
      "Bob reported performance issues being optimized, with fixes expected by Friday. Charlie requested finalized messaging by Monday for marketing preparation. Bob confirmed an early stable build would be ready.\n",
      "\n",
      "Conclusion:\n",
      "The team aligned on next steps: engineering finalizing fixes, marketing preparing content, and a follow-up sync scheduled for Wednesday.\n",
      "\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Format Correctness [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">⚠ WARNING:</span> No hyperparameters logged.\n",
       "» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m⚠ WARNING:\u001b[0m No hyperparameters logged.\n",
       "» \u001b]8;id=593532;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Evaluation completed 🎉! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>64s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001272</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   » Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» Want to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Evaluation completed 🎉! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m1.\u001b[0m64s | token cost: \u001b[1;36m0.001272\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   » Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» Want to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate using G-Eval\n",
    "print(\"--- Running G-Eval ---\")\n",
    "g_eval_result = evaluate([test_case], [metric_g_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b4aedea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Score: 1.0\n",
      "Extracted Reason:\n",
      "The actual output contains all required headings: 'intro', 'body', and 'conclusion', and they are\n",
      "presented in the correct order. Each section is clearly labeled and the content under each heading\n",
      "is relevant and complete, fully aligning with the evaluation steps.\n"
     ]
    }
   ],
   "source": [
    "# Print the score and reason\n",
    "print(f\"Extracted Score: {g_eval_result.test_results[0].metrics_data[0].score}\")\n",
    "print(f\"Extracted Reason:\")\n",
    "print(textwrap.fill(g_eval_result.test_results[0].metrics_data[0].reason, width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a117fa4",
   "metadata": {},
   "source": [
    "## What is Coming Up in Session 3 \n",
    "<span style=\"font-size:20px;\">Two important practical use cases</span>    \n",
    "- <span style=\"font-size:18px;\">RAG Evaluation End-to-End</span>  \n",
    "  \n",
    "- <span style=\"font-size:18px;\">Agent Evaluation End-to-End</span>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb4a2c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
